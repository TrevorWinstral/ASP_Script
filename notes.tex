\documentclass[12pt]{book}
\usepackage[utf8]{inputenc}
\usepackage{amsmath, amssymb, amsfonts, amsthm}
\usepackage{bbm}
\usepackage{url}
\usepackage{geometry}
 \geometry{
 a4paper,
 left=20mm,
 right=20mm
 }

\usepackage{mathtools}
\mathtoolsset{showonlyrefs}

\usepackage{xcolor}
\definecolor{linkcolour}{rgb}{0,0.2,0.6}

\usepackage{hyperref}
\hypersetup{colorlinks,breaklinks,urlcolor=linkcolour, linkcolor=linkcolour}

\renewcommand{\iff}{\Leftrightarrow}

\newtheorem{theorem}{Theorem}[section]
\newtheorem{prop}[theorem]{Proposition}
\newtheorem{cor}[theorem]{Corollary}
\newtheorem{lemma}[theorem]{Lemma}

\theoremstyle{definition}
\newtheorem{defn}{Definition}[section]

\theoremstyle{remark}
\newtheorem{ex}{Example}[section]
\newtheorem{rmk}[theorem]{Remark}

\usepackage{enumitem}
\setenumerate[1]{label=(\roman*)}


\title{Applied Stochastic Processes Notes}
\author{Trevor Winstral}
\date{Spring Semester 2021}

\begin{document}
\maketitle
\tableofcontents 
\newpage

\section{Introduction}

\textbf{Mathematical Definition of Stochastic Processes} We want to describe a process evolving in time. The most relevant for us will be: Discrete time ($I=\mathbb{N}$) and Continuous time ($I=\mathbb{R}$).

\begin{defn}
	Let $(E, \xi)$ be a measurable space. A discrete stochastic process with state space $E$ is a collection $X=(X_n)_{n \in \mathbb{N}}$ of RVs with values in $E$.
\end{defn}

\begin{defn}
A continuous stochastic process is a collection $(X_t)_{t \in \mathbb{R}_+}$ of RVs with values in $E$.
\end{defn}

In this class we will work with jump processes, ie when $E$ is finite or countable.
We will work with:
\begin{enumerate}
	\item Discrete time Markov Chains $I=\mathbb{N}$ and $E$ finite or countable
	\item Poisson renewal processes $I=\mathbb{R}_{+}$ and $E= \mathbb{N} $
	\item Continuous Markov Chains $I= \mathbb{R}_{+}$ and $E$ finite or countable
\end{enumerate}
We will not work with Brownian Motion.

\begin{ex}[Simple Random Walk] 
	State Space $\mathbb{Z}^{d}$, $x,y$ are neighbors $\iff \|x-y\|_{1}=1$. An electron is starting at 0, and each step it jumps uniformly to one of the neighbors. How should we define this?

\end{ex}

\begin{defn}[SRW]
	Let $(Z_n)_{n \in \mathbb{N}}$ iid, $\mathbb{P} \left[ Z_n = \pm e_i \right] = \frac{1}{2d}$ where $e_i$ is 1 in the i'th slot. $X_n := \sum_{k=1}^n Z_n= X_n + Z_{n+1}, X_0=1$. $\forall m,n X_m$ and $X_n$ are dependent.  The $X_n$ do satisfy the Markov property: Conditional on $X_n=x$ then $(X_{m+n})_{n \geq 0}$ is a SRW starting at $x$ independent of $(X_1,...,X_m)$.
\end{defn}

Will the SRW return to 0?
\begin{theorem}[Polya]\ \\ \indent
	If $d=1,2$ then $\mathbb{P} \left[ (X_n) \text{ visits x infinitely many times} \right] =1$ \\ \indent
	If $d\geq3$ then $\mathbb{P} \left[ (X_n) \text{ visits x only finitely many times} \right] =1$
\end{theorem}

\begin{ex}[Poisson Process]
	We want to define and study $N_t$ the number of cars passing a point during $[0,t]$.
\end{ex}

\begin{defn}
	$T_1 =$ passage of time of the first car, $T_2=$ time between car 1 and car 2, etc. 
\begin{itemize}
	\item $(T_i)$ are iid
	\item $(T_i)$ are memoryless:  $\mathbb{P} \left[ T_1 \geq t+s | T_1 \geq s \right] = \mathbb{P} \left[ T_1 \geq t \right] $ 
	\item Regularity: $\mathbb{P} \left[ T_1 \geq s \right] $ is 'nice'
\end{itemize}
This implies that $\mathbb{P} \left[ T_1 \geq s \right] = e^{- \lambda s}, \quad \lambda>0$
\end{defn}

Let $(T_i)_{i\geq1}$ iid $exp(\lambda)$ RV. $N_t = \sum_{i\geq1}\chi_{T_1 + ... + T_i \leq t}$ \newline
Dependencies:
\begin{itemize}
	\item $N_{t+s}-N_t \sim Pois(\lambda s)$
	\item Markov Property
\end{itemize}
LLN: $ \frac{N_t}{t} \to_{t \to \infty} \frac{1}{\lambda}$



\newpage
\section{Markov Chains and Generalities}
\textbf{Framework}: $\Omega, F, \mathbb{P}$ Probability Space, $E$ finite or countable set with the $\sigma$-algebra $2^E$

\noindent
\textbf{Outset} We would like to define a class of processes such that the evolution of the process is path independent, but still location dependent. This means that the way a process continues past this point in time, does not depend on how it got to where it is now, but only on where it is at this point in time. 

\begin{defn}
	A sequence $X_n, n \in \mathbb{N}$ of RVs with values in $E$ is a homogeneous time Markov Chain (MC) if:
\begin{enumerate}
    \item  $\forall n \geq 0, \forall x_1,...,x_{n+1}\in E, \quad \mathbb{P} \left[ X_{n+1}=x_{n+1} | X_0=x_0,...,X_n=x_n \right] = \mathbb{P} \left[ X_{n+1}=x_{n+1} | X_n = x_n \right] $
	\item $\forall m,n \geq 0 \forall x,y \in E, \quad \mathbb{P} \left[ X_{n+1}=y | X_{n}=x \right] = \mathbb{P} \left[ X_{n+1=y}| X_n=x \right] $
\end{enumerate}

\end{defn}


By convention when we write $\mathbb{P} \left[ A|B \right] $ we assume $\mathbb{P} \left[ B \right] >0$.

\begin{rmk}
The first condition is eqv to $\forall f:E\to \mathbb{R} bdd, \mathbb{E} \left[ f(X_{n+1}) | X_0,...,X_n \right] = \mathbb{E} \left[ f(X_{n+1}) | X_n \right] $
\end{rmk}

\begin{ex}
	If $X_n$ are iid in $E$ then $X_n$ is a MC
\end{ex}

\begin{ex}
	SRW on $\mathbb{Z}^d$
\end{ex}

\subsection{Transition Probabilities}
\textbf{Motivation} In a finite state space $E=\{1,2,3\}$, then we write the probability to go from 1 to 2 as $p_{12}$. We would like to write these probabilities in a matrix.

\begin{defn}
	A transition probability is a collection $p=(p_{x,y})_{x,y \in E}$ st:
	\begin{itemize}
		\item $\forall x,y: p_{x,y}\in [0,1]$ 
		\item $\sum_{y \in E} p_{x,y}=1$
	\end{itemize}
	
\end{defn}

We could also represent this as a weighted directional graph with vertices $E$ and weighted oriented edges: $\{(x,y) \in E: p_{x,y}>0\}$. We know there is a 1 to 1 correspondence between directional graphs and matrices.

\textbf{Matrix} So say $E=\{1...N\}$ and $p=(p_{ij})_{1\leq i,j\leq N}$ with $p_{ij}\geq 0$ and $\sum_{j}p_{ij}=1$. We call this a stochastic matrix.

\textbf{Operator} If $E$ is finite or infinite then $\forall f \in L^\infty (E)$ define $Pf \in L^\infty (E)$ by  $\forall x \in E Pf(x)=\sum_{y \in E}P_{x,y}f(y)$ with $P\geq 0 $ ($\forall  f \geq 0: Pf \geq 0$ ) and satisfies $P1=1$.

\begin{defn}
	Let $p$ be a transition probability, $\psi$ distribution on $E$, a sequence $(X_n)_{n\geq 0}$ of RVs with values in $E $ is a Markov Chain with initial distribution $\mu$ and transition probability $p$ (written $MC(\psi, p)$) if:
	$\forall  x_0...x_n \in E: \mathbb{P} \left[ X_0=x_0...X_n=x_n \right] = \mu(x_0)p_{x_0,x}*...*p_{x_{n-1},x_{n}}$

\end{defn}

\begin{prop}
	Let $(X_n)_{n \geq 0}$ seq of RV with values in E:
	$(X_n)_{n \geq 1}$ is a MC $\iff$ $\exists \mu, p\ st\ (X_n)_n$ is a MC$(\mu, p)$
\end{prop}
\begin{proof}
	$\implies:$ If $X_n$ is a MC, then set $p_{xy}=\mathbb{P}_{} \left[ X_{n+1}=y | X_{n}=x \right] $. $\sum_{y \in E}^{} p_{xy}=1$, as the conditional probability is a probability measure itself, and $p_{xy}\geq 0, \forall x, y \in E$ for the same reason. Thus we have that the collection of $(p_{xy})_{x,y \in E}$ form a transition probability. Setting $\mu(x) = \mathbb{P}_{} \left[ X_0 =x \right] $, which is also clearly a probability measure on $E$. Now we only have to show that $X_{n} $ is a $MC(\mu, p)$. For every $x_0,\ldots , x_n \in E$, and every $n\geq 0$, we have
\begin{align}
	\mathbb{P}_{} \left[ X_0=x_0...X_n=x_n \right]  
	&= \mathbb{P}_{} \left[ X_n = x_n | X_0=x_0 ... X_{n-1}=x_{n-1} \right] \mathbb{P}_{} \left[ X_0=x_0 ... X_{n-1}=x_{n-1} \right] \\
	&= \mathbb{P}_{} \left[ X_0 = x_0 \right] \prod_{i=1}^{n} \mathbb{P}_{} \left[ X_i = x_i | X_0=x_0... X_{i-1}=x_{i-1} \right] \\
	&= \mu(x_0) \prod_{i=1}^n \mathbb{P}_{} \left[ X_i = x_i | X_{i-1} = x_{i-1}  \right] = \mu(x_0) \prod_{i=1}^n p_{x_{i-1}x_{i}} 
\end{align}
Thus we have proven this implication, by using the Markov Property of Markov Chains.

$\impliedby:$ Here we have to show the two aspects of a Markov chain, the Markov Property and homogeneity. For homogeneity we have:
\begin{gather}
	\mathbb{P}_{} \left[ X_{n+1} = y | X_n =x \right] \\
	= \sum_{(u_0...u_{n-1}) \in E^n}^{} \mathbb{P}_{} \left[ X_{n+1}=y | X_0=u_0...X_{n-1}=u_{n-1}, X_n =x \right] \mathbb{P}_{} \left[ X_0=u_0... X_{n-1}=u_{n-1} | X_n = x \right] \\
	= p_{xy} \sum_{(u_0...u_{n-1})\in E^n}^{} \mathbb{P}_{} \left[ X_0=u_0...X_{n-1}=u_{n-1} | X_n = x \right] = p_{xy}
\end{gather}
here we have implicitly (sneakily) assumed that $\mathbb{P}_{} \left[ X_n = x \right] > 0$, as without this the conditional probability we are taking is not well-defined.

For the Markov Property we have:
\begin{align}
	\mathbb{P}_{} \left[ X_{n+1}=x_{n+1} | X_0=x_0...X_n=X_n \right] \\
	=\frac{\mathbb{P}_{} \left[ X_0=x_0... X_{n+1}=x_{n+1} \right] } {\mathbb{P}_{} \left[ X_0=x_0 ... X_{n}=x_{n} \right]} = \frac{\mu(x_0)p_{x_0x_1} ... p_{x_{n}x_{n+1}}} {\mu(x_0)p_{x_0x_1}...p_{x_{n-1}x_{n}}} \\
	= p_{x_nx_{n+1}} = \mathbb{P}_{} \left[ X_{n+1} = x_{n+1} | X_n=x_n \right] 
\end{align}
where it is important to note that, again,  we have implicitly assumed that \newline $\mu(x_0)p_{x_0x_1}...p_{x_{n-1}x_n}>0$. 

\end{proof}


\textbf{Question} Given $\mu, p$ does $MC(\mu, p)$ always exist (as a MC)?

\subsection{Existence}

\begin{theorem}
	Let $p$ be a transition probability on $E$. Then there exists:
\begin{enumerate}
	\item a measurable space $(\Omega, F)$
	\item a collection of prob meas $(P_x)_{x}$ on $(\Omega, F)$
	\item a seq of RV $(X_n)_{n \geq 0}$ on $(\Omega, F)$ st $\forall \in E$ under $P_x$, $(X_n)$ is  $MC(\delta_x, p)$
\end{enumerate}

\end{theorem}

There are 2 approaches to prove this. 

One could set $\Omega = E^{\mathbb{N}}, \quad \mathbb{P} \left[ (x_0...x_n) | x \in E^n \right] = \delta_x(x_0) p_{x_0,x_1}...p_{x_{n-1},x_n}$.
Instead we will work as follows:
\begin{proof}
	We consider a measure $\mu $ on $E$ such that $\forall x \in E: \mu (x) >0$ on some abstract probability space (this part is of technical relevance) $(\Omega, \mathcal{F}, \mathbb{P} )$. Now we look at a RV $X_0$ with distribution $\mu$, and $U_1,U_2,...$ independent, uniformly distributed, RVs on $[0,1]$ (we know these exist from previous probability lectures). Our goal is to use these uniform RVs to produce the probabilities given by the transition probabilities, in a way similar to Sklar's Theorem (knowledge of Sklar's is not needed here). To do this we enumerate $E=\{x_i, i \in I \}$ where $I$ is our index set (eg. $\{1,2,...,n\}$ or  $\mathbb{N}$) and set $s_{ij}= \sum_{k<j}p_{x_ix_k} $. Note here that $s_{i,j+1}-s_{i,j} = p_{x_ix_j} $. Finally, set $\Phi: E \times [0,1] \to E; (x_i,u) \mapsto x_j $ if $u \in (s_{i,j}, s_{i,j+1}]$, a measurable function. Now we have $X_0$ as needed and the tools to construct the sequence of RVs, along with the collection of probability measures we want.

	What these tools have given us is that $\mathbb{P}_{} \left[\Phi(x,U_1) = y  \right] = p_{xy}$. So if we set $X_{n+1} = \Phi(X_n, U_{n+1})$ for every $n>0$ (by induction), we find that:
\begin{gather}
	\mathbb{P}_{} \left[ X_0=x_0...X_n=x_n \right] = \mathbb{P}_{} \left[ X_0=x_0, \Phi(x_0, U_1)=x_1 ... \Phi(x_{n-1}, U_{n}) = x_n \right] \\
	= \mu(x_0)p_{x_0x_1}...p_{x_{n-1}x_n}
\end{gather}
by independence.

Now if we define $\mathbb{P}_{x} $ as $\mathbb{P}_{} \left[\ \cdot\ | X_0 = x_0 \right] $, then we have $\forall x \in E$ $\mathbb{P}_{x} \left[ X_0=x_0...X_n=x_n \right] = \delta_x(x_0)p_{x_0x_1}...p_{x_{n-1}x_n}$.


\end{proof}


\noindent
\textbf{Framework for the rest of the chapter} 
$E$ is finite or countable, $p$ transition probability, $(\Omega, F, (P_x)_{x \in E})$ Prob. Spaces, $(X_n)_{n \geq 0}$ RV st it is a  $MC(\delta_x, p)$ under $P_x$.

For $\mu$ Prob measure on $E $ we write $P_\mu= \sum_{x}\mu(x)P_x$

\subsection{Simple Markov Property}
Under $P_\mu$ $(X_n)_{n \geq 0}$ is $MC(\mu, p)$.
$P_\mu [X_{n+1}=x_{n+1} | X_0 = x_0....X_n=x_n] = P_\mu[X_{n+1}=x_{n+1}| X_n = x_n] = P_{x_n}[X_1 =x_{n+1}]$ ie Conditional on $X_n=x$, $x_{n+1}$ is sampled like the first step of a $MC(\delta_{x},p)$ indep of the past.

\textbf{Notation} $ \mathcal{F}_n = \sigma(X_0...X_n)$ 

\begin{theorem}[Simple Markov Property (SiMP)]
	Let $\mu$ be a distribution on E. Let $x \in E, k \in \mathbb{N}$. For every $f: E^{\mathbb{N}} \to \mathbb{R}_+$ meas bdd, for every $Z$ bdd which is $F_k$ meas RV:

	$\mathbb{E}_\mu \left[ f((X_{k+n})_{n \geq 0})Z | X_k = x_k \right] = \mathbb{E}_{x_k} \left[ f((X_n)_{n \geq 0} \right] \mathbb{E}_\mu \left[ Z | X_k=x \right] $
\end{theorem}
\begin{proof}
	First note that using $Z= \mathbbm{1}_{X_0=x_0...X_{k-1}=x_{k-1}}$ we only have to prove that \newline $\mathbb{E}_{\mu } \left[ f((X_{k+n})_{n\geq 0}) | X_0=x_0 ... X_k=x_k \right]= \mathbb{E}_{x_k} \left[ f((X_n)_{n\geq 0}) \right]$. We will proceed using measure theoretic induction (see any book on measure theory). Approximate $f$ by step functions $f_k$, using linearity, we only have to show our claim for the function $\mathbbm{1}_{A} $ with $A \subset E ^{\mathbb{N}}$, ie. 
	\begin{gather}
	\mathbb{P}_{\mu } \left[ (X_{k+n})_{n\geq 0}\in A | X_0=x_0...X_k=x_k \right] = \mathbb{P}_{x_k} \left[ (X_n)_{n\geq 0} \in A \right] 
\end{gather}  
The collection of sets of the form $A=\{w \in E^{\mathbb{N}}: w_0=y_0...w_N=y_N\}$ for $N\geq 0$ and $y_0,...,y_N \in E$ form a $\pi $ system generating our $\sigma$-algebra. Furthermore, on such sets 
\begin{align}
&	\mathbb{P}_{\mu } \left[ (X_{k+n})_{n\geq 0}\in A | X_0 = x_0...X_k=x_k \right] \\
&\qquad= \mathbb{P}_{\mu} \left[ X_k=y_0...X_{k+N}= y_N | X_0=x_0...X_k=x_k  \right] \\
&\qquad= \frac{\mu (x_0) p_{x_0x_1}...p_{x_{k-1}x_k} \delta_{x_k}(y_0)p_{y_0y_1}...p_{y_{N-1}y_N}}{\mu (x_0) p_{x_0x_1}...p_{x_{k-1}x_k} } \\
& \qquad= \delta_{x_k}(y_0)p_{y_0y_1} \cdots p_{y_{N-1}y_N} \\
& \qquad= \mathbb{P}_{x_k} \left[ (X_n)_{n\geq 0} \in A \right] 
\end{align}
Dynkin's Lemma then allows us to extend this property to the entire $\sigma$-algebra.
\end{proof}


\begin{cor}
	$\mu$ distribution on $E$, $x \in E$, $k \in \mathbb{N}$, $\forall f: E^{\mathbb{N}} \to \mathbb{R}$ meas bdd:
	$\mathbb{E}_\mu \left[ f((X_{k+n})_{n \geq 0} | X_k =x \right] = \mathbb{E} _x \left[ f((X_n)_{n \geq 0} \right]  $
\end{cor}

\noindent
\subsection{n-Step Transition Probabilities}
\begin{defn}
	For every $n\geq0$, $x, y \in E$, define $p_{xy}^{(n)}=P_x[X_n=y]$
\end{defn}

\begin{prop}[Chapman Kolmogorov (CK)]
\begin{equation}
	\forall m,n \geq 0 \ \forall x,y \in E \quad \boxed{ p_{xy}^{(m+n)}= \sum_{z \in E} p_{xz}^{(m)}p_{zy}^{(n)}}
\end{equation}
	
\end{prop}
\begin{proof}
Fix $m,n$ and $x,y \in E$.
	\begin{align}
		p_{xy}^{(m+n)} =\mathbb{P}_{x} \left[ X_{m+n}=y \right] = \sum_{z \in E}^{} \mathbb{P}_{x} \left[ X_{m+n} | X_m = z \right] \mathbb{P}_{x} \left[ X_m = z \right] \\
		\stackrel{\textrm{(SiMP)}}{=} \sum_{z \in E}^{} \mathbb{P}_{z} \left[ X_n=y \right] \mathbb{P}_{x} \left[ X_m=z \right] = \sum_{z \in E}^{} p_{xz}^{(m)} p_{zy}^{(n)}  	
	\end{align}
	
\end{proof}


\begin{rmk}[]
	If $E$ is finite:
\itemize
\item The matrix $(p_{ij}^{(n)})_{ij \leq 0}=P^n$
\item $\forall  \mu$ distribution on $E: \forall f:E \to \mathbb{R}; \forall n \geq0$:\quad $\mathbb{E}_{\mu} \left[ f(X_n) \right] = \mu P^n f$, with $f = [f(1),...,f(n)]^T$
\end{rmk}

\subsection{Stationary Distributions}
\textbf{Motivation}: write $\mu_{n}$ as the law of $X_{n}$ under $P_{\mu}$, $\mu_0=\mu$ and $\mu_{n+1}=\mu_{n}P$. For $n$ large $\mu_n$ is a fixed point of the map $\lambda \to \lambda P = \left( \sum_{x \in E} \lambda(z)p_{xy} \right)_{y \in E}$

\begin{defn}
	Let $\pi$ be a distribution on $E$, we say that $\pi$ is stationary (for $p$) if:
\begin{equation}
	\forall y \in E: \pi(y) = \sum_{x \in E} \pi(x)p_{xy}
\end{equation}

\textbf{Linear Algebra interpretation} If $E$ is finite and we write  $\pi = [\pi(1)...\pi(n)]^T$, then $\pi$ is stationary $ \iff$ $\pi P = \pi$ ie $\pi$ is a left eigenvector of P for the eigenvalue 1.

\textbf{Probabilistic interpretation} If $\pi $ is a stationary distribution, then $\forall n \geq 0$ $P_{\pi }[X_n =x] = \pi (x)$
\newline \indent
Basically, no matter how far along you are in the chain, the probability that you land on a value $x$ is equal to the probability that you start at $x$.
\end{defn}

\subsection{Reversibility}
\begin{defn}
	A distribution $\pi $ on $ E$ is said to be reversible (for $p$) if:
\begin{equation}
	\forall x,y \in E: \pi (x) p_{xy}= \pi (y)p_{yx}
\end{equation}
The probability of starting at $y$ and going to $x$ is equal to the probability of starting at $x$ and going to $y$. More generally, one can prove by induction that $\pi $ is reversible $ \iff \forall n; \forall x_0...x_n: \mathbb{P}_{\pi } \left[ X_0=x_0...X_n=x_n \right] = \mathbb{P}_{\pi } \left[ X_0=x_n...X_n=X_0 \right] $
\end{defn}

\textbf{Motivation} We want an easy criterion for invariance, such reversible systems appear often in physics.

\begin{prop}[]
	Let $\pi $ be a distribution on $E$, then $\pi $ reversible $\implies \pi $ is stationary
\end{prop}
\begin{proof}
	\begin{gather}
		\sum_{x \in E}^{} \pi (x)p_{xy} = \sum_{x \in E}^{} \pi (y) p_{yx} = \pi (y) \sum_{x \in E}^{} p_{yx} = \pi(y) 
	\end{gather}
	
\end{proof}

\begin{ex}[Gas in Containers]
	Imagine there are two containers $A$ and $B$ with gas particles, between them is a small hole through which the particles can pass through. At every step a single particle is selected uniformly at random and passes through this hole. To represent this mathematically, let $X_n$ be the number of particles in $A$ at time $n$, and let there be $N$ total particles. $X_n$ is a Markov Chain, proving this is straightforward, we can see that the system is autonomous (time plays no role, only the state of the system) and path-independent (again only the current state of the system matters in its evolution in the next step). The transition probabilities are given by $p_{x, x+1}= 1- \frac{x}{N}$, as in order for $X_n$ to grow by 1, the randomly selected particle must be from container $B $; this occurs with probability $\frac{\# \textrm{ of particles in }B}{\# \textrm{ of total particles}} = \frac{N-x}{N}$. The only other option is for the amount of particles in $A$ to decrease by 1, by the fact that the transition probabilities must sum to 1 we find: $p_{x, x-1}= \frac{x}{N}$. Now we wonder if it is possible to find a stationary distribution, this would represent the equilibrium distribution of particles (see the different interpretations above). To find this distribution, we instead simplify and see if we can find a reversible distribution, ie. $\pi (x) p_{x,x+1} = \pi (x+1)p_{x+1, x}$. We then use this to calculate $\pi (x)$ explicitly and see if this defines a proper distribution. 
	\begin{gather}
		\pi (x+1) = \frac{\pi (x)(1 - \frac{x}{N})}{\frac{x+1}{N}} = \pi (x) \frac{N-x}{x+1} \stackrel{\textrm{(Induction)}}{=} \pi (0) \frac{N ...(N-x)}{(x+1)!} 
	\end{gather}
Thus we find that $\pi (x) = \binom{N}{x}\pi(0)$, so we have to find $\pi (0)$ such that $\pi $ is a distribution. 
\begin{gather}
	\sum_{x \in E}^{} \pi (x) \stackrel{!}{=}1 \implies \pi (0) = \left( \sum_{x \in E}^{} \binom{N}{x} \right)^{-1} = \frac{1}{2^N} 
\end{gather}	
Hence, $\pi (x)= \binom{N}{x} \frac{1}{2^N}$, the binomial distribution; which is (as we have shown) reversible. When $X_{n+1} \sim X_n$ (equilibrium) then the number of particles in $A$ is $\sim Bin(N, \frac{1}{2})$.
\end{ex}


\subsection{Communication Classes}
Here we will will see $p$ as a weighted oriented graph.
\begin{defn}
	Let $x,y \in E$. Write:
\itemize
\item $x \to y$ if $\exists  n \geq 0$ st $p_{xy}^{(n)}> 0$ "y can be reached from x"
\item $x \leftrightarrow y$ if ($x \to y$ and  $y\to x $) "x and y communicate"
\end{defn}

\begin{prop}[]
	$\leftrightarrow$ is an equivalence class on E
\end{prop}
\begin{proof}
	Let $x,y,z \in E$ and $m,n \geq 0$ such that $p_{xy}^{(m)}>0$ and $p_{yz}^{(n)}>0$.
\begin{enumerate}
	\item Transitivity: $p_{xz}^{(m+n)} \geq p_{xy}^{(m)}p_{yz}^{(n)} >0 \implies x\rightarrow z$, same for the other direction 
	\item Reflexivity: $p_{xx}^{(0)} = \mathbb{P}_{x} \left[ X_0 = x \right] =1>0 \implies x \leftrightarrow x$ 
	\item Symmetry: Trivial
\end{enumerate}
\end{proof}


\begin{defn} \hfill
\begin{itemize}
\item The equivalence classes of $\leftrightarrow$ are called communication classes.
\item The chain $p$ is called irreducible if there is a unique communication class.
\end{itemize}
\end{defn}

\noindent
\textbf{Motivation} We will see that $p$ irreducible $\implies p$ has at most one stationary distribution.

\begin{defn}
	A communication class $C$ is closed if 
\begin{equation}
\forall x,y \in E: x \in C, x \to y \implies y \in C
\end{equation}
ie. if you start in $C$ you never leave.
\end{defn}

\subsection{Strong Markov Property}
%$F_n=\sigma(X_0...X_n)$ 
	
\begin{defn}
	Let $T:\Omega \to \mathbb{N} \cup \{+\infty\}$ RV with values in $\mathbb{N}\cup\{+\infty\}$. We say that $T$ is an ($ \mathcal{F}_n$)-stopping time if:
	\begin{align}
		\forall n \in \mathbb{N}: \{T=n\} \in \mathcal{F}_n
	\end{align}
	
\end{defn}

\begin{ex}[Stopping Times]
	$H_{A}=inf(n \geq 0: X_n \in  A)$ (for $A$ measurable) and $H_x=inf(n\geq 0: X_n = x)$ are stopping times.
\end{ex}

\begin{defn}
	Let $T$ be a stopping time. $ \mathcal{F}_T=\{A \in \mathcal{F}: \forall n \in \mathbb{N}: \{T=n\}\cap A \in \mathcal{F}_n \}$
\end{defn}

\begin{theorem}[Strong Markov Property (SMP)]
	Let $\mu $ be a distribution on $E$, $T$ an $ \mathcal{F}_n$-stopping time. Let $x \in E$,
	$\forall f:E^{\mathbb{N}} \to \mathbb{R}$ meas and bdd, $\forall Z$ which are $ \mathcal{F}_T$ meas and bdd, we have:
\begin{align}
	\mathbb{E}_{\mu } \left[ f((X_{T+n})_{n\geq 0}) \cdot Z | T<\infty, X_T=x \right] = \mathbb{E}_{x} \left[ f((X_n)_{n\geq 0}) \right]  \mathbb{E}_{\mu } \left[ Z | T<\infty, X_T=x \right] 
\end{align}

\end{theorem}
\noindent
"Conditioned on $\{T<\infty,X_T=x\}$, $(X_{T+n})_{n\geq 0}$ is a $MC(\delta_x,p)$ indep of $F_T$ "
\begin{proof}
We will multiply each side of the equation by $\mathbb{P}_{} \left[ T < \infty, X_T =x \right]$.
\begin{gather}
	\mathbb{E}_{\mu } \left[ f((X_{T+n})_{n\geq 0})Z \mathbbm{1}_{T<\infty, X_T=x}  \right] = \sum_{k\geq 0}^{} \mathbb{E}_{\mu } \left[ f((X_{k+n})_{n\geq 0} Z \mathbbm{1}_{T=k, X_T=k}  \right] \\
	= \sum_{k\geq 0}^{} \mathbb{E}_{\mu } \left[ f((X_{k+n})_{n\geq 0}) Z \mathbbm{1}_{T=k} | X_k = x \right] \mathbb{P}_{\mu } \left[ X_k = x  \right] \\ 
	\stackrel{\text{SiMP}}{=} \sum_{k\geq 0}^{} \mathbb{E}_{x} \left[ f((X_{n})_{n\geq 0}) \right] \mathbb{E}_{\mu } \left[ Z \mathbbm{1}_{T=k, X_k = x}  \right] \\
	= \mathbb{E}_{x} \left[ f((X_n)_{n\geq 0} \right] \sum_{k\geq 0}^{} \mathbb{E}_{\mu } \left[ Z \mathbbm{1}_{T=k, X_k=x}  \right]  
	= \mathbb{E}_{x} \left[ f((X_n)_{n\geq 0}) \right] \mathbb{E}_{\mu } \left[ Z \mathbbm{1}_{T<\infty, X_T=x}  \right] 
\end{gather}
\end{proof}


\noindent
\textbf{Application} Reflection Principle for the SRW.
Consider the SRW on $\mathbb{Z}$: 

\begin{prop}[]
	Let $k\geq 0$ even, $a\geq1$ odd: $\mathbb{P}_{0} \left[ max\{X_m: 0 \leq m \leq k \} \geq a \right] = \mathbb{P}_{0} \left[ |X_k|\geq a \right]  $
\end{prop}
\begin{proof}
	Define $H_a= min\{n \geq 1: X_n =a\}$, this is a stopping time.
	\begin{gather}
		\mathbb{P}_{0} \left[ \max_{0 \leq m \leq k}X_m \geq a \right] = \mathbb{P}_{0} \left[ H_a \leq k \right] = \mathbb{P}_{0} \left[ X_k > a \right]  + \mathbb{P}_{0} \left[ H_a \leq k, X_k < a \right] 
		\end{gather}
		Now our goal is to show the term on the right is equal to $\mathbb{P}_{0} \left[ X_k > a \right] $, as $2\mathbb{P}_{0} \left[ X_k > a \right] = \mathbb{P}_{0} \left[ |X_k| >a \right] $ by symmetry. We can go from $>$ to $\geq$ because $a$ is even and $k$ is odd. At this point we note that $X_{H_a +n} \sim a + (a-X_{H_a +n}) = 2a - X_{H_a +n}$. Geometrically, this means that if we only look at the walk after hitting $a$, the walk has the same distribution if we inverse the direction of each step: 'looking path after hitting $a$, we cannot tell if it is the normal or the inverted step walk'.
	\begin{gather}
		\mathbb{P}_{0} \left[ H_a \leq k, X_k < a \right] = \sum_{m=0}^{k} \mathbb{P}_{0} \left[ X_k < a, H_a = m \right] = \sum_{m=0}^{k} \mathbb{P}_{a} \left[ X_{k-m} < a \right] \mathbb{P}_{0} \left[ H_a = m \right]  \\
		= \sum_{m=0}^{k} \mathbb{P}_{0} \left[ X_{k-m}<0 \right] \mathbb{P}_{0} \left[ H_a = m \right] = \sum_{m=0}^{k} \mathbb{P}_{0} \left[ X_{k-m}>0 \right] \mathbb{P}_{0} \left[ H_a = m \right] \\
		= \sum_{m=0}^{k} \mathbb{P}_{a} \left[ X_{k-m}>a \right] \mathbb{P}_{0} \left[ H_a = m \right] = 
		 \sum_{m=0}^{k} \mathbb{P}_{0} \left[ X_{k-m}>a, H_a =m \right] \\
		= \mathbb{P}_{0} \left[ X_k >a, H_a \leq k \right] = \mathbb{P}_{0} \left[ X_k > a \right]  
	 \end{gather}
	
\end{proof}


\noindent
\textbf{Conclusion} Now we have properly defined a Markov Chain, shown its existence, and introduced some concepts to help classify different types of chains. Importantly, we have also introduced the transition probability framework. 

\newpage
\section{Markov Chains: Long Time Behavior}

\noindent \textbf{Outset} With the tools and classification concepts introduced previously, we would like to expand upon these to rigorously classify chains.

\noindent \textbf{Framework:} $E$ finite or countable, $p=(p_{xy})x,y \in E$ transition probabilities, ($\Omega, F, (\mathbb{P}_x) _{x \in E}$), $X=(X_n)_{n\geq 0} \sim MC(\delta_x,p)$ under $\mathbb{P}_x$, $\mathbb{P}_\mu = \sum_{}^{} \mu (x)\mathbb{P}_x$.

\noindent \textbf{Questions:} 
\begin{itemize}
	\item When does there exist a stationary distribution?
	\item What is the behavior of $X_n$ for $n$ large?
	\item If we fix $x \in E$, will the chain visit $x$ infinitely many times?
\end{itemize}

\subsection{Recurrence/Transience}

\textbf{Notation} $H_x = min\{n\geq 1: X_n=x\}$
\begin{defn}
	Let $x \in E$, we say that:
\begin{itemize}
	\item $x$ is recurrent if $\mathbb{P}_{x} \left[ H_x<\infty \right]=1 $
	\item $x$ is transient if $\mathbb{P}_{x} \left[ H_x<\infty \right] <1$ 
\end{itemize}

\end{defn}
\noindent
\textbf{Notation:} For $x \in E$ write $V_x=\sum_{n\geq 0}^{} \mathbbm{1}_{X_n=x} $, ie the total number of visits.

\begin{theorem}[Dichotomy Theorem]
	$x \in E$:
\begin{itemize}
	\item if $x$ is recurrent, then $V_{x}=+\infty$ $P_x$-a.s.
	\item if $x$ is transient, then $\mathbb{E}_{x} \left[ V_x \right] <\infty$
\end{itemize}
\end{theorem}

\begin{rmk}[]
It is impossible that $\mathbb{P}_{x} \left[ V_x<\infty \right] >0 $ and $\mathbb{E}_{x} \left[ V_x \right] =+\infty$.
\end{rmk}


\begin{defn}
	$\rho_x = \mathbb{P}_{x} \left[ H_x<\infty \right]$, if $x$ is recurrent then $\rho_x=1$, otherwise if $x$ is transient $\rho_x<1$.Thus the number of visits is a geometric RV with parameter $\rho_x<1$ 
\end{defn}

\begin{lemma}[]
	For every $i\geq 0, x \in E$, we have $\mathbb{P}_{x} \left[ V_x \geq i \right] = \rho_x^{i}$.
\end{lemma}

\begin{proof}[Proof (Lemma)]
	We will proceed by induction over $i$. Define $H_x^{(i)}$ to be the $i$-th hit time of $x$. For $i=0$ the claim is clear.
	\begin{gather}
		\mathbb{P}_{x} \left[ V_x \geq i+1 \right] = \mathbb{P}_{x} \left[ V_x \geq i+1 \wedge V_x \geq i \right] = \mathbb{P}_{x} \left[ H_x^{(i_1)} < \infty \wedge H_x^{(i)} < \infty \right] \\
		= \mathbb{P}_{x} \left[ H_x^{(i+1)} < \infty | H_x^{(i)} < \infty, X_{H_x^{(i)}}=x \right] \mathbb{P}_{x} \left[ H_x^{(i)} < \infty \right] \\
		\stackrel{\text{StMP}}{=} \mathbb{P}_{x} \left[ H_x^{(1)} < \infty \right] \rho_x^i = \rho_x^{i+1}   
	\end{gather}
\end{proof}

\begin{proof}[Proof (Theorem)]
	For $x$ recurrent: 
	\begin{gather}
		\mathbb{P}_{x} \left[ V_x = \infty \right] = \mathbb{P}_{x} \left[ \bigcap_{i=0}^{\infty} \{V_x \geq i\} \right] = \lim_{i\to \infty} \mathbb{P}_{x} \left[ V_x \geq i \right] = \lim_{i \to \infty} \rho_x^{i} = 1 
	\end{gather}
	For $x$ transient:
	\begin{gather}
		\mathbb{E}_{x} \left[ V_x \right] = \sum_{k=0}^{\infty} k \mathbb{P}_{x} \left[ V_x = k \right] = \sum_{k=1}^{\infty} \sum_{j=1}^{k} \mathbb{P}_{x} \left[ V_x=k \right] \stackrel{(*)}{=} \sum_{j=1}^{\infty} \sum_{k=j}^{\infty} \mathbb{P}_{x} \left[ V_x=k \right] \\
		= \sum_{j=1}^{\infty} \mathbb{P}_{x} \left[ V_x \geq j \right] = \sum_{j=1}^{\infty} \rho_x^k = \frac{\rho_x}{1-\rho_x} < \infty
	\end{gather}
	To justify (*) intuitively, we will write the values we are summing over in a table. In the sum on the left we sum over each row first (the inner sum), collect these values in a column, and then sum over that column (outer sum); meanwhile for the RHS we first sum over each column, collect these values in a row, and then sum over that row.	
	\begin{gather*}
	\begin{matrix}
	\mathbb{P}_{x} \left[ V_x = 1 \right] & & & & \sum=\sum_{j=1}^{1} \mathbb{P}_{x} \left[ V_x =1 \right]  \\
	\mathbb{P}_{x} \left[ V_x = 2 \right] & \mathbb{P}_{x} \left[ V_x =2 \right] & & & \sum = \sum_{j=1}^{2} \mathbb{P}_{x} \left[ V_x = 2 \right]  \\
	\mathbb{P}_{x} \left[ V_x = 3 \right] & \mathbb{P}_{x} \left[ V_x =3 \right] &  \mathbb{P}_{x} \left[ V_x=3 \right] & & \sum = \sum_{j=1}^{3} \mathbb{P}_{x} \left[ V_x =3 \right]  \\
	& & & & \vdots \\ 
	\vdots & \vdots & & & \sum_{k=1}^{\infty} \sum_{j=1}^{k} \mathbb{P}_{x} \left[ V_x = k \right] \\
	\sum_{k=1}^{\infty} \mathbb{P}_{x} \left[ V_x =k \right] & \sum_{k=2}^{\infty} \mathbb{P}_{x} \left[ V_x=k \right]  &  ...  & \sum_{j=1}^{\infty} \sum_{k=j}^{\infty} \mathbb{P}_{x} \left[ V_x = k \right]  
	\end{matrix}
	\end{gather*}
	Such tricks with sums will be used again.
\end{proof}

\begin{prop}[]
	If $E$ is finite, then there exists a recurrent state $x \in E$.
\end{prop}
\begin{proof}
	Fix some $y \in E$.
	\begin{gather}
		\sum_{x \in E}^{} V_x = \sum_{n=0}^{\infty} \sum_{x \in E}^{} \mathbbm{1}_{X_n =x} = \sum_{n\geq 0}^{} 1  = \infty \\
	\sum_{x \in E}^{} \mathbb{E}_{y} \left[ V_x \right] = \mathbb{E}_{y} \left[ \sum_{x \in E}^{} V_x \right] = \infty \\
	\end{gather}
	Thus we know $\exists x \in E$ such that $\mathbb{E}_{y} \left[ V_x \right] = \infty$ since the sum on the left is over a finite index set ($E$ finite). Since we can write $V_x = V_x \mathbbm{1}_{H_x<\infty}$, we find that (Strong Markov Property) $\infty = \mathbb{E}_{y} \left[ V_x \right] = \mathbb{E}_{y} \left[ V_x \mathbbm{1}_{H_x<\infty}  \right] = \mathbb{E}_{x} \left[ V_x \right] \mathbb{P}_{y} \left[ H_x < \infty \right] $, because a walk started from $y$ is the same (in the distribution sense) after hitting $x$ for the first time as a walk started from $x$. $\mathbb{P}_{y} \left[ H_x < \infty \right]$ must be $ \leq 1 $, thus the term of the left must be equal to $\infty \implies \mathbb{E}_{x} \left[ V_x \right] = \infty$.
\end{proof}


\subsection{Recurrence/Transience for the SRW on $\mathbb{Z}^d$}
\textbf{SRW on $\mathbb{Z}^d$:} $E=\mathbb{Z}^d$, $p_{xy}=\frac{1}{2d}\ if\ \|x-y\|_1=1, 0\ else$ 

\begin{theorem}[]
	For the SRW, every state is recurrent if $d=1,2$, otherwise they are transient.
\end{theorem}

\subsection{Classification of States}
\begin{theorem}[]
	Let $x,y \in E$ st $x \to y$. If $x $ is recurrent then $y$ is recurrent and $\mathbb{P}_{x} \left[ H_y<\infty \right] = \mathbb{P}_{y} \left[ H_x<\infty \right]=1 $.
	In particular $x \leftrightarrow y$.
\end{theorem}

\begin{rmk}[]
	$x \neq y: x \to y \iff \mathbb{P}_{x} \left[ \exists n: X_n=y \right] \iff \mathbb{P}_{x} \left[ H_y<\infty \right] $
\end{rmk}

\begin{cor}[]
	Let $C$ communication class for p. Either $\forall x$: $x$ is recurrent, or $\forall x$: x is transient.
\end{cor}

\begin{cor}[]
	A recurrent class is always closed.
\end{cor}

\subsection{Positive/Null Recurrence}
\textbf{Notation} $x \in E: m_{x}=\mathbb{E}_{x} \left[ H_x \right] $

\begin{defn}
	Let $x \in E$ be a recurrent state. We say that:
\begin{itemize}
	\item positive recurrent if $m_x<\infty$ 
	\item null recurrent if $m_x=+\infty$
\end{itemize}

\end{defn}

\begin{theorem}[]
	Let $x,y \in E, x \leftrightarrow y$. Then $\lim_{n \to \infty}\frac{1}{n}\sum_{k=1}^{n} p_{xy}^{(k)}=\frac{1}{m_{y}}$
\end{theorem}
\begin{rmk}[]
	Write $V_{y}^{(n)}=\sum_{k=1}^{n} \chi_{X_k=y}$, "The number of visits to $y$ up to time $n$". Thus the sum in the theorem is "Expected proportion of time spent at $y$".
\end{rmk}

If $y$ is transient, null recurrent ($m_y=\infty$), the theorem tells us that $\lim_{n \to \infty}\mathbb{E}_{x} \left[ \frac{V_y^{(n)}}{n} \right] =0$: "null density of visit"

\begin{defn}[inter-visit times]
	Let $y \in E$. Define $H_y^{0}=H_y$ and $\forall i\geq 1: H_{y}^{i}= min\{n \geq 1: X_{H_y^0 + ... + H_y^{i-1}+n}=y\}$ if $H_y^{i-1}<\infty$, else $+\infty$	
\end{defn}

\begin{lemma}[]
	Let $x,y$ st. $x \leftrightarrow y$, assume $y$ is recurrent. Then $\forall j \geq 1, t_0...t_j \in \mathbb{N}$:
\begin{align}
	\mathbb{P}_{x} \left[ H_y^0=t_0...H_y^j=t_j \right] = \mathbb{P}_{x} \left[ H_y=t_0 \right] \mathbb{P}_{y} \left[ H_y=t_1 \right] ... \mathbb{P}_{y} \left[ H_y=t_j \right] 
\end{align}
Under $P_x$, $H_y^1,H_y^2,...$ are iid with law $\mathbb{P}_{x} \left[ H_y^i=t \right] = \mathbb{P}_{y} \left[ H_y=t \right] $
\end{lemma}

\begin{prop}[Classification of recurrent classes]
	Let $R$ be a recurrent class. Then either:
\begin{itemize}
	\item $\forall x \in R: x$ is positive recurrent
	\item $\forall x \in R: x$ is null recurrent
\end{itemize}

\end{prop}

\begin{prop}[]
	Let $R$ be a recurrent class, if $R$ is finite, then $R$ is positive recurrent.
\end{prop}

\subsection{Stationary Distributions for Irreducible Chains}
\begin{theorem}[]
	Assume that $p$ is irreducible. 
\begin{itemize}
	\item If the chain is transient or null recurrent, then there is no stationary distribution.
	\item if the chain is positive recurrent, then there exists a unique stationary distribution given by $\forall x \in E: \pi (x) = \frac{1}{\mathbb{E}_{x} \left[ H_x \right] }$
\end{itemize}

\end{theorem}

\subsection{Periodicity}
\begin{defn}
	Let $x \in E$. The period of $x$ is defined by $d_x = gcd\{n\geq 0: p_{xx}^{(n)}>0\}$
\end{defn}

\begin{prop}[]
	Let $x,y \in E: x \leftrightarrow y \implies d_x=d_y$
\end{prop}

\textbf{Consequence} if p is irreducible we have $\forall x,y \in E: d_x = d_y$ 

\begin{defn}
	We say that the chain $p$ is aperiodic if $\forall x \in E: d_x=1$
\end{defn}

\begin{prop}[]
	Let $x \in E$. We have $d_x=1 \iff \exists n_0 \geq 1 \textrm{ st } \forall n \geq n_0: p_{xx}^{(n)}>0$
\end{prop}

\subsection{Coupling Method}
\textbf{What is coupling?}
Define probability measures $\mu_1, \mu_2$ on the same space $F_1,F_2$. A coupling between $\mu_1$ and $\mu_2$ is a probability measure $\overline{\mu }$ on $F_1 \times F_2$, 
$\overline{\mu }(A \times F_2)=\mu_1(A)$ and vice versa. 

$X_1, X_2$ two random variables on $(\Omega, F, \mathbb{P}) $, $X_1 \sim \mu_1, X_2 \sim \mu_2$, the law of $(X_1,X_2)$ is a coupling!

\noindent
\textbf{Goal} Define two MCs: $X_n \sim MC(\mu, p), \quad \tilde{X_n} \sim MC(\nu, p) $ on the same probability space st $X_n = \tilde{X_n}$ for n large.

\begin{defn}[Product Chain]
	Define $\forall \omega=(x,y), \quad \omega'=(x',y') \in E^2$: $\overline{p_{\omega, \omega'}}=p_{xx'}p_{yy'}$
\end{defn}

\noindent
\textbf{Notation} Consider:
\begin{itemize}
	\item $(\Omega, F, (P_\omega)_{\omega \in E^2})$ Probability Spaces
	\item $(W_n)_{n\geq 0}=((X_n,Y_n))_{n\geq 0}$ RV on $\Omega, F$ st $\forall \omega \in E^2: W_n$ is a $MC(\delta_\omega, \overline{p})$ under $P_w$
\end{itemize}

\begin{rmk}[]
	If $\mu, \nu $ are distributions on $E$, then $\mu \otimes \nu $ is a distribution on $E^2$. $P_{\mu \otimes \nu }= \sum_{(x,y)\in E^2}^{}\mu (x) \nu (y) P_{(x,y)} $
\end{rmk}

\begin{prop}[]
	Let $\mu,\nu $ be distributions on $E$. Under $P_{\mu \otimes \nu }:$ 
\begin{itemize}
	\item $(X_n)_{n\geq 0}$ is a $MC(\mu ,p)$ 
	\item $(Y_n)_{n\geq 0}$ is a $MC(\nu ,p)$
\end{itemize}

\end{prop}

\begin{prop}[]
	If $p$ is irreducible and aperiodic, then $\overline{p}$ is irreducible and aperiodic.
\end{prop}

\begin{rmk}[]
	Aperiodic is important!  $p$ irreducible $\nRightarrow \overline{p}$ irreducible.
\end{rmk}

\begin{prop}[]
	If $p$ is irreducible, aperiodic, and positive recurrent, then $\overline{p}$ is irreducible, aperiodic, and positive recurrent.
\end{prop}

\begin{defn}
	$T=min\{n\geq 0: X_n=Y_n\}$ a stopping time.
\end{defn}

\begin{prop}[]
	$\forall \mu, \nu $ distributions on $E $: 
\begin{align}
\forall n\geq 0 \sum_{x \in E}^{} |\mathbb{P}_{\mu } \left[ X_n=x \right] - \mathbb{P}_{\nu} \left[Y_n=x  \right] | \leq 2 \mathbb{P}_{\mu \otimes \nu } \left[ T>n \right]
\end{align}
\end{prop}

\begin{lemma}[]
	$\tilde{X}_n = Y_n\chi_{\{T<n\}} + X_n \chi_{\{T \geq n\}} $ is a $MC(\nu, p)$
\end{lemma}

\subsection{Convergence for Irreducible Aperiodic Chains}
\begin{theorem}[]
	Assume $p$ is irreducible and aperiodic, and admits a stationary distribution $\pi $. Then for every distribution $\mu$ on $E$ : $\lim_{n \to \infty}\mathbb{P}_{\mu } \left[ X_n=x \right] = \pi(x), \forall x \in E$. 

	\noindent
	Equivalently: Under $P_\mu: $ $X_n \stackrel{(law)}{\to} X_\infty$ where $X_\infty \sim \pi$ 

	\noindent
	Equivalently: $\forall f:E \to \mathbb{R}$ bdd: $\lim_{n \to \infty} \mathbb{E}_{\mu } \left[ f(X_n) \right] = \int_{E}^{} f d \pi$
\end{theorem}
\textbf{Note} This theorem is important!! 

\begin{theorem}[]
	Assume that $p$ is irreducible, aperiodic, and null recurrent or transient. Then for every distribution $\mu $ and every $x \in E:$ $\lim_{n \to \infty}\mathbb{P}_{\mu } \left[ X_n =x \right] = 0$ 
\end{theorem}
\begin{lemma}[]
	$\overline{p}$ irreducible and recurrent, then $\forall \mu $ distribution on $E: \forall i\geq 0, \forall x \in E:\, \lim_{n \to \infty} | \mathbb{P}_{\mu } \left[ X_n=x \right] - \mathbb{P}_{\mu } \left[ X_{n+i}=x \right] | = 0$
\end{lemma}

\noindent \textbf{Conclusion} We previously asked the following questions:
\begin{itemize}
	\item If we fix $x \in E$, will the chain visit $x$ infinitely many times?
	\item What is the behavior of $X_n$ for $n$ large?
\end{itemize}
Now we are equipped to answer them using our ideas of recurrence/transience and the theorem for existence (and uniqueness) of stationary distributions for an irreducible chain. We were also found that using coupling we find that if we let the chain evolve for a long time, then the distribution of $X_n$ actually converges to the stationary distribution (where this distribution is 0 everywhere if a stationary distribution does not exist).

\section{Renewal Processes}
\textbf{Outset} We want to model replacement times of a machine. First we wait $T_1$ until we replace it, then we wait $T_2$ until replacing the replacement, and so on.

\noindent
\textbf{Questions:} After time $t$, how many replacements did we have to make ($N_t$)? What about the expected number $m(t)=\mathbb{E}_{} \left[ N_t \right] $?
What about the 'excess time', ie if we are at time $t$, how long until the next replacement ($E_t$, $e(t)=\mathbb{E}_{} \left[ E_t \right]$)? Or the age of the machine ($A_t$, $a(t)=\mathbb{E}_{} \left[ A_t \right] $).

Case 1: $T_1... \sim Exp(\lambda)$: $m(t)=t\lambda$, $E_t \sim Exp(\lambda), e(t)= \frac{1}{\lambda}$, $A_t \sim Exp(\lambda)$.

Case 2: More complicated.

\subsection{Definition and First Properties}
\textbf{Framework} $(\Omega, \mathcal{F}, \mathbb{P})$ Probability space, $T_1, T_2,...$ iid RVs on $\mathbb{R}_+$ 'inter-arrival times', st $\mathbb{P}_{} \left[ T_i = 0 \right] < 1$, $\mu = \mathbb{E}_{} \left[ T_1 \right] \in (0, \infty]$. $F(t) =  \mathbb{P}_{} \left[ T_1 \leq t \right] $, $S_n = \sum_{i=1}^{n} T_i, S_0 =0$ 'renewal times'.
\begin{defn}
	The continuous stochastic process $(N_t)_{t\geq 0}$ defined by:
\begin{align}
	\forall t \geq 0: N_t = \sum_{k=1}^{\infty} \mathbbm{1}_{S_k \leq t}
\end{align}
is called the renewal process with arrival distribution $F$.
\end{defn}

\begin{ex}[]
	\begin{enumerate}
		\item $pp(\lambda ), \lambda> 0, T_i \sim Exp(\lambda)$
		\item $(T_i)_{i\geq 1}$ iid $Exp(\lambda)$, $(X_i)_{i\geq 1}$ iid $Ber(\frac{1}{2})$, $T_i'= X_i T_i$, where  $(T_i)$ and  $(X_i)$ are indep.
		\item 'Fat Tailed' $\mathbb{P}_{} \left[ T_{i} \geq t \right] = \frac{1}{\sqrt{1+t}} \mathbbm{1}_{t\geq 0}$
	\end{enumerate}
	
\end{ex}

\begin{prop}[]
	$N = (N_t)_{t\geq 0}$ is a counting process with jump times $S_1, S_2,...$ and $\lim_{t \to \infty} N_t = + \infty$.
\end{prop}

\begin{prop}[]
	There exists $c> 0$ st $\forall t\geq 0: \mathbb{E}_{} \left[ e^{cN_t} \right] \leq e^{\frac{1+t}{c}}$, thus the expectation is finite $\forall t$.
\end{prop}

\begin{theorem}[Law of Large Numbers]
	We have $\lim_{t \to \infty} \frac{N_t}{t} = \frac{1}{\mu}$.
\end{theorem}

\subsection{Renewal Function}
\begin{defn}
	The renewal function is defined by $\forall t\geq 0: m(t) = \mathbb{E}_{} \left[ N_t \right] $.
\end{defn}

\begin{rmk}[]
	$m(t)<\infty$ because $N _t$ has exponential moment (you can use Jensen).
\end{rmk}

\begin{prop}[]
	$m(t)$ is non-decreasing, non-negative, and right continuous.
\end{prop}

\begin{theorem}[Elementary Renewal Theorem]
	$\lim_{t \to \infty} \frac{m(t)}{t}=\frac{1}{\mu }$
\end{theorem}

\subsection{Blackwell's Renewal Theorem}
\begin{defn}
	We say the law of $T_1$ is arithmetic if $\exists a > 0: \mathbb{P}_{} \left[ T_1 \in a \mathbb{Z} \right] =1$. It is non-arithmetic if this probability is $<1$.
\end{defn}

\begin{theorem}[Blackwell]
	Assume that the law of $T_1$ is non-arithmetic, then $\lim_{t \to \infty} m(t+h)-m(t) = \frac{h}{\mu }$.
\end{theorem}

\begin{rmk}[]
	$ \frac{m(t)}{t} \approx \frac{m(\lfloor t \rfloor)}{\lfloor t \rfloor} = \frac{1}{\lfloor t \rfloor} \sum_{k=1}^{\lfloor t \rfloor} m(k) - m(k-1) \stackrel{Blackwell}{\to} \frac{1}{\mu}$. "Blackwell is stronger than elementary renewal."
\end{rmk}

\subsection{Renewal Equation}

\subsubsection{Lebesgue-Stieltjes Integral} 
\textbf{Notation} $ \mathcal{M} = \{ f: \mathbb{R}_+ \to \mathbb{R}_+, \textrm{right continuous, non-decreasing}\}$ 'measures on $\mathbb{R}_+$ '. $\nu((a,b])=f(b)-f(a)$

For all $h \in L^1(df)$ or $h\geq 0$ meas, we can define $\int h df$.

\begin{ex}[]
\begin{itemize}
	\item $m \in \mathcal{M} \to \int h dm$ can be defined	
	\item If $T$ is a RV on $\mathbb{R}_+$ the $F_T(t) = \mathbb{P}_{} \left[ T \leq t \right] $
\end{itemize}

\end{ex}

\begin{defn}
	Let $G \in \mathcal{M}$. Let $h: \mathbb{R}_+ \to \mathbb{R}$ st either $\forall t: \int_{0}^{t}| h(t-s) | dG(s) < \infty $ or $h\geq 0$ a.e. we define:
\begin{align}
	h*G = \int_{0}^{t} h(t-s)dG(s)
\end{align}

\end{defn}

\begin{rmk}[]
	Let $X,Y$ be two indep RV on $\mathbb{R}_+$. Then with  $F_X, F_Y$ their respective cdf's: 
\begin{align}
	\mathbb{P}_{} \left[ X+Y \leq t \right] =& \int_{s=0}^{t} \mathbb{P}_{} \left[  X+s \leq t \right] dF_y(s) \\
	=& \int_{0}^{t} F_X(t-s)dF_Y(s)
\end{align}
So $F_{X+Y} = F_X * F_Y$.
\end{rmk}

Why is this useful?
\begin{align}
	m(t) =& \mathbb{E}_{} \left[ N_t \right] = \mathbb{E}_{} \left[ \sum_{n}^{} \mathbbm{1}_{T_1+...T_n \leq t} \right] \\
	=& \sum_{n}^{} F_{T_1 +...+T_n} (t) = F^{*n}(t).
\end{align}

\subsubsection{Renewal Equation}
\begin{defn}
	Let $h:\mathbb{R}_+ \to \mathbb{R}$ meas. loc. bdd, $g:\mathbb{R}_+ \to \mathbb{R}$ st $ \forall t\geq 0: \int_{0}^{t} |g(t-s)|dF(s) <\infty$. We say that $g$ is a solution of the $(h,F)$ renewal equation if:
\begin{align}
	\forall t\geq 0: g(t) = h(t) + \int_{0}^{t} g(t-s)dF(s)
\end{align}
\end{defn}

\begin{prop}[First Example]
	$m$ is a solution of the $(F,F)$ renewal equation, ie $m=F+m*F$.	
\end{prop}

\begin{ex}[Excess Time, 2nd Example]
	$E_t = S_{N_{t+1}}-t$, the time left to wait until next renewal. Define for  $x \geq 0$, $e_x(t) = \mathbb{P}_{} \left[ E_t \leq x \right] $. We can separate $e_x$ into 2 parts, one for the probability if there has already been a renewal before time $t$, and one if that hasn't occured: $e_x(t) = \mathbb{P}_{} \left[ T_1 > t, E_t \leq x \right]  + \mathbb{P}_{} \left[ T_1 \leq t, E_t \leq x \right]  = A + B$.

	$A = \mathbb{P}_{} \left[ T_1 > t, T_1 \leq t+x \right] = F(t+x)-F(t)$. Observe that $E_t$ is meas wrt $T_1, T_2,...$. $E_t = \phi_t(T_1,T_2,...)$. 
\begin{align}
	\mathbb{P}_{} \left[ T_1 \leq t, E_t \leq x \right] =& \mathbb{P}_{} \left[ T_1 \leq t, \phi_t(T_1,T_2,...) \leq x \right] \\ 
	=& \int_{0}^{t} \mathbb{P}_{} \left[ \phi_t(s, T_2,...) \leq x \right] dF(s) = \int_{0}^{t} \mathbb{P}_{} \left[ E_{t-s} \leq x \right] dF(s) \\
	=& \int_{0}^{t} e_x(t-s) dF(s) = (e_x * F)(t)
\end{align}
Thus $e_x(t) = h_x(t) + (e_x * F)(t)$ with $h_x(t) = F(t+x)-F(t)$. So  $e_x$ is a solution of the $(h_x,F)$ renewal equation.
\end{ex}

\textbf{Exercise} Show that the age $a_x(t) = \mathbb{P}_{} \left[ A_t \leq x \right] $ is the solution to some $(h,F)$ renewal equation.

\subsubsection{Well-Posedness of the Renewal Equation}
\begin{theorem}[]
	Let $h: \mathbb{R}_+\to \mathbb{R}$ meas, loc bdd. Then there exists a unique $g: \mathbb{R}_+ \to \mathbb{R}$ meas, loc bdd, solution of $g = h + g*F$ given by $g=h+h*m$. 
\end{theorem}
\begin{proof}[Intuitive Proof]
	Assume $g$ is a solution. 
\begin{align*}
	g =& h + g*F \\
	=& h + (h+g*F)*F \\
	... \\
	\stackrel{(*)}{=}& h + h*F + h*F^{*2} + h*F^{*3}+... \\
	=& h + h*m
\end{align*}
We must only show that $(*)$ can be made rigorous. Otherwise this is just an intuitive proof, we can use this as a way to find a candidate for $g$, and then prov that it is actually a legitimate solution as follows.
\end{proof}
\begin{proof}[Rigorous Proof]
	$g = h + h*m$ is meas. loc. bdd., because  $h$ is. We have $h + g*F = h + (h+h*m)*F = h + h*F + h*m*F=h+h*(F+m*F)=h+h*m = g$	

\textbf{Uniqueness} 
$g_1, g_2$ are 2 solutions, then $g_1-g_2 = (g_1 - g_2)*F = (g_1 - g_2) * F^{*n}$. We have for every $t \geq 0: |g_1(t) - g_2(t)| = \left| \int_{0}^{t} (g_1 - g_2)(t-s)dF^{*n}(s) \right| \leq sup_{[0,t]} |g_1 - g_2| \int_{0}^{t} dF^{*n}(s)$. Where we can see the integral term is equal to $\mathbb{P}_{} \left[ T_1 +... +T_n \leq t \right] $ which converges to 0.
\end{proof}

\subsection{Asymptotic Behavior}

\textbf{Motivation} We want to study the behavior of $g(t)$ when  $t$ is large and when $g$ is a solution to the $(h,F)$ renewal equation.

\textbf{Case 1} $h=\mathbbm{1}_{[a,b]} $, and $g$ a solution. $g(t) = h(t) + \int_{0}^{t} h(t-s)dm(s)$. $h(t-s) = \mathbbm{1}_{[a,b]}(t-s) = \mathbbm{1}_{s \in [t-b, t-a]}$. So $g(t) = h(t) + m(t-a)-m(t-b)$ and with Blackwell's Theorem we find that this tends towards $0+\frac{b-a}{\mu}$. Now we need to figure out how this generalizes.

\textbf{Idea} Extend to simple functions $\sum_{}^{} \lambda_i \mathbbm{1}_{I_i}$ (this is easy), then try to extend to directly integrable Riemann functions.

\begin{defn}
	$h: \mathbb{R}_+ \to \mathbb{R}_+$ meas., $h$ is directly Riemann Integrable (dRi) if $\forall \Delta >0: \sum_{k=0}^{\infty}\Delta sup_{[k \Delta, (k+1)\Delta]} h < \infty$ and $lim_{\Delta \to 0} \Delta \sum_{k=0}^{\infty} sup_{[k \Delta,(k+1)\Delta] } h = lim _{\Delta \to \infty} \Delta \sum_{k=0}^{\infty} inf_{[k \Delta, (k+1)\Delta]}h$. $h: \mathbb{R}_+ \to \mathbb{R}_+$ is dRi iff $h_+$ and $h_-$ are dRi. See notes for example for integrable but not dRi function.
\end{defn}

\begin{prop}[]
	Let $h: \mathbb{R}_+ \to \mathbb{R}$. Assume that $h$ is continuous at a.e. $t \in \mathbb{R}$, $\exists H$ non-decreasing st $0 \leq |h| \leq H$ and $\int_{0}^{\infty} H < \infty$, then $h$ is dRi. 
\end{prop}

\begin{theorem}[Smith Key Renewall Theorem]
	Let $h$ be dRi, $F$ non-arithmetic. Then $g=h+h*m$ satisfies $lim_{t \to \infty}g(t)= \frac{1}{\mu } \int_{0}^{\infty} h(u) du$.
\end{theorem}

\begin{rmk}[]
	The case $h= \mathbbm{1}_{[0,b]}$ corresponds to the Blackwell Theorem. 
\end{rmk}

The idea of the proof is to use an approximation of $h$ by functions of the form $h_{c,\Delta}=\sum_{k\geq 0}^{} c_k \mathbbm{1} _{[k\Delta, (k+1)\Delta)}$.

\textbf{Application} Let $\mu < \infty$. Let $E_t$ be the excess time (time until next renewal) and $e_x(t) = \mathbb{P}_{} \left[ E_t \leq x \right] $. What is $lim_{t \to \infty} e_x(t)$? We know that $e_x = h_x + e_x*F$, where $h_x(t) = F(t+x)-F(t)$.

\begin{rmk}[]
	$\mu = \mathbb{E}_{} \left[ T_1 \right] = \int_{0}^{\infty} \mathbb{P}_{} \left[ T_1 > t \right] dt$
\end{rmk}

With this we have that $h_x(t) \leq 1 - F(t) = \mathbb{P}_{} \left[ T_1 > t \right] $, and $1-F(t)$ is non-increasing in $t$ and continuous ae (because it is the difference of two monotone functions). $\int_{0}^{\infty} \mathbb{P}_{} \left[ T_1 > t \right] dt = \mathbb{E}_{} \left[ T_1 \right] = \mu < \infty $. So (by the proposition) $h_x$ is dRi. Now we can apply the theorem and get that $lim_{t \to \infty} \mathbb{P}_{} \left[ E_t \leq x \right] = \frac{1}{\mu } \int_{0}^{\infty} h_x(t)dt = \frac{1}{\mu } \int_{0}^{\infty} F(t+x) - F(t) dt$, with $F(t+x) - F(t) = \mathbb{E}_{} \left[ \mathbbm{1}_{T_1 \in (t, t+x]} \right] $, we find that the limit is equal to $\frac{1}{\mu } \int_{0}^{\infty} \mathbb{E}_{} \left[ \mathbbm{1}_{T_1 \in (t, t+x]} \right]dt = \frac{1}{\mu} \mathbb{E}_{} \left[ \int_{0}^{ \infty } \mathbbm{1}_{t \in [T_1 -x, T_1)}    \right]dt = \frac{1}{\mu } \mathbb{E}_{} \left[ \int_{max\{T_1-x, 0\}}^{T_1} dt \right] =  $ $T_1$ if $T_1 \leq x$ and $x$ if  $T_1 > x$. Thus we get for $t$ large:  $\mathbb{P}_{} \left[ E_t \leq x \right] \approx  \frac{1}{\mu} \mathbb{E}_{} \left[ min\{T_1, x\} \right]  $. 

\begin{rmk}[]
	$G(x) = \frac{1}{\mu } \mathbb{E}_{} \left[ min\{T_1, x\} \right] $ is the delay distribution in the proof of Blackwell's Theorem.
\end{rmk}

\noindent \textbf{Conclusion} We have now used renewal processes to define a general structure to model a real life process mathematically. Using this object enabled us to implement the LLN and make statements about the asymptotic behavior of such processes over large periods of time.

\section{General Poisson Point Processes}
\textbf{Reference} Lectures on the Poisson Process (Penrose), Poisson Processes (Kingman)

\subsection{Introduction}
\textbf{Question} How can we represent points on $\mathbb{R}_+$ mathematically?
\begin{enumerate}
	\item A set of points $\mathcal{S}=\{S_1, S_2,...\}$ \label{q:3}
	\item 'Time point of view', ie $T_1,T_2,...$ where $T_i$ = time between the $(i-1) $'th and $i $'th point. \label{q:1}
	\item Cadlag formulation with values in $ \mathbb{N}$. $N_t=$ number of points in $[0,t]$. \label{q:2}
	\item Measure $N: \mathcal{B}(\mathbb{R}_+) \to \mathbb{N}$ with $N(A)=$ number of points in $A$. \label{q:4}
\end{enumerate}
\textbf{Goal} Define $\Omega \to $'set of points'. For a general state space $\mathbb{R}^2, [0,1]^2,$ a manifold, etc. 
\ref{q:1} and \ref{q:2} are specific to $\mathbb{R}_+$, so they do not generalize. \ref{q:3} is not very easy to describe. \ref{q:4} is actually nice, so we will  use this point of view.

\textbf{Framework} $(E,d)$ a Polish space (separable, complete, metric space). $\mathcal{E}$ Borel $\sigma$-algebra. $\mu: \sigma$ finite measure on $(E, \mathcal{E})$, ie  $\exists  B_i \uparrow E: \mu(B_i)<\infty$ where $B_i \uparrow E \iff B_1 \subset B_2 \subset...: \bigcup_{i\geq 1}B_i=E$.

\begin{ex}[] Of such spaces: 
\begin{enumerate}
	\item $E=\{0\}, \mu = \delta_0$
	\item $E=\mathbb{R}_+, \mu = \lambda \mathcal{L}$
	\item $E=\mathbb{R}^2, \mu(dx)=\frac{1}{\pi} e^{- |x|^2}dx$ 'Gaussian'
\end{enumerate}
\end{ex}

\textbf{Goal} We wish to define a point process on $(E, \mathcal{E})$ where the 'number of points around $x$ ' $\approx \mu(dx)$ on $\mathbb{R}_+$. 

\subsection{Point Processes}
\textbf{Notation} $\mathcal{N}=\{\nu: \nu=\sigma-$finite measure st $\forall B \in \mathcal{E}: \nu(B) \in \mathbb{N} \cup \{+\infty\}\}$.
\noindent
\textbf{Measure Structure} Let $\mathcal{B}(\mathcal{N})$ be the $\sigma$-algebra generated by the sets $\{\nu \in \mathcal{N}: \nu(B)=k\}=\mathcal{N}_k$ for $B \subset E$ meas and $k \in \mathbb{N}$. $\to (\mathcal{N}, \mathcal{B}(\mathcal{N}))$ measured space.

\begin{prop}[]
	Let $\mathcal{N}_{<\infty}=\{\nu \in \mathcal{N}: \nu(E)<\infty \}$, there exists meas maps $\tau: \mathcal{N}_{< \infty} \to \mathbb{N}, X_i: \mathcal{N}_{< \infty} \to E$ st $\forall \nu \in \mathcal{N}_{<\infty}: \nu = \sum_{i=0}^{\tau(\nu)} \delta_{X_i(\nu)}$.
\end{prop}

\begin{defn}
	A point process on $(E, \mathcal{E})$ is a RV $N$ with values in $ \mathcal{N}$. '$N$ is a random $\sigma$-finite measure', $N \leftrightarrow$ 'random set of points'. 
\end{defn}
This means $N: \Omega \to \mathcal{N} $ meas, for any fixed $B \subset E: N(B): \Omega \to \mathbb{N}\cup \{+\infty\}$ is measurable. 
Thus a stochastic process corresponds to $(N(B))_{B \in \mathcal{E}}$. '$N(B)=$ number of points in B'.

\begin{ex}[] Point Processes:
\begin{itemize}
	\item $N=0$ a.s.  $\to$ empty set
	\item $E=[0,1], X$ RV on  $[0,1]$.  $N=\delta_X$ is a point process.
	\item $X_1,...X_n$ iid RV on $[0,1]$,  $N=\delta_{X_1}+...+\delta_{X_n}$ is a point process.
\end{itemize}
\end{ex}

\subsection{Poisson Point Processes}
\textbf{Setup} $(E, \mathcal{E})$ Polish, $\mu$ fixed $\sigma$-finite measure (think of $\lambda \mathcal{L}$ ), $ \mathcal{N}=\{\sigma$ finite counting measure$\}$, $(\Omega, F, \mathbb{P} )$ abstract prob space.

\begin{defn}
	A Poisson process with intensity $\mu$ on $(E, \mathcal{E})$ ($ppp(\mu)$) is a point process st:
 \begin{enumerate}
	 \item $\forall B_1...B_k \subset E$ meas and disjoint: $N(B_1)...N(B_k)$ are indep.
	 \item $\forall B \subset E$ meas $N(B) \sim Pois(\mu(B))$.
\end{enumerate}
\end{defn}

\subsection{Existence and Uniqueness}
\textbf{Question} Does there always exist a $ppp(\mu)$ on $E$?
\subsubsection{Spaces with finite measure}
\begin{prop}[]
	Let $Z \sim Pois(\mu(E))$, $(X_i)_{i\geq 1}$ iid where $X_i \sim \frac{\mu(.)}{\mu(E)}$. Then $N= \sum_{i=1}^{Z} \delta_{X_i} $ is a $ppp(\mu)$ on $E$.
\end{prop}

\subsubsection{Superposition}
\begin{lemma}[]
	Let $\lambda = \sum_{i=1}^{\infty} \lambda_i, \lambda_i\geq 0$. $X_i \sim Pois(\lambda_i), i \geq 1$ indep, then $X = \sum_{i=1}^{\infty} X_i \sim Pois(\lambda)$.
\end{lemma}

\begin{theorem}[]
	Let $N_i, i\geq 1$ be a sequence of indep $ppp(\mu_i)$ where $\mu_i$ and $\mu = \sum_{i=1}^{\infty} \mu_i$ are $\sigma$-finite measures. Then $N= \sum_{i=1}^{\infty} N_i$ is a $ppp(\mu )$.
\end{theorem}

\begin{cor}[]
	$\mu \ \sigma$-finite measure on $(E, \mathcal{E})$, then $\exists\ ppp(\mu)$ on $E$.
\end{cor}

\subsubsection{Uniqueness}
Let $N$ be a $ppp(\mu )$ on $E$, define $P_N = $ law of $N$ ($\rightarrow$ a probability meas on $ \mathcal{N}$).

\begin{prop}[]
	Let $N, N'$ be two $ppp(\mu )$ on $(E, \mathcal{E})$ then $P_N = P_{N'}$.
\end{prop}

\begin{theorem}[Representation of ppp as Proper Processes]
	Let $N$ be a $ppp(\mu )$ on $(E, \mathcal{E})$, there exists some RV $\tau \in \mathbb{N} \cup \{+\infty \}$ st: $X_n \in E, n\geq 1: N = \sum_{i=1}^{\tau(} $
\end{theorem}

\subsection{Laplace Functional}
$N$ a random meas on $(E, \mathcal{E})$ for $u:E \to \mathbb{R}$ what should we interpret $\int_E u dN$ as?

\begin{lemma}[]
	$X \sim Pois(\lambda ), \lambda > 0$, then $\forall u\geq 0: \mathbb{E}_{} \left[ e^{-u X} \right] = exp( - \lambda (1 - e^{-u}))$.
\end{lemma}

\begin{defn}
	Let $N$ be a point process on $(E, \mathcal{E})$, for every $u:E\to \mathbb{R}_+$ define $L_N(u) = \mathbb{E}_{} \left[ exp(- \int u(x) N(dx) \right] $
\end{defn}

\begin{rmk}[]
	$\int_E u(x) N(dx) = \int_E u dN$ is a RV.
\end{rmk}

\begin{theorem}[Characterization via Laplace Functional]
	Let $\mu \ \sigma$-finite meas on $(E, \mathcal{E})$. Let $N$ be a point process on $E$. TFAE:
\begin{enumerate}
	\item $N$ is a $ppp(\mu)$ 
	\item $\forall u:E \to \mathbb{R}_+$ meas: $L_N(u) = exp(- \int_E 1- e^{-u(x)} \mu (dx))$
\end{enumerate}

\end{theorem}

\subsection{Simple Processes}
\begin{rmk}[]
	For $x \in E,\ \{x\}$ is meas. because $E$ is Polish.
\end{rmk}

\begin{defn}
	A measure $\eta \in \mathcal{N}$ is said to be simple if $\forall x \in E: \eta(\{x\}) \leq 1$.
\end{defn}

\begin{prop}[]
	$\{\eta: \eta$ is simple$ \}$ is measurable in $ \mathcal{N} $.
\end{prop}

\begin{theorem}[]
	Assume that $\mu $ is a diffuse ($\forall x: \mu (\{x\}=0$) $\sigma$ finite measure. Then every $ppp( \mu )$ is simple a.s.
\end{theorem}

\textbf{Consequence} $\exists \tau,\ X_i$ RV, $X_i \neq X_j$ if $i \neq j$ a.s.: $N=\sum_{i=1}^{\tau} \delta_{x_i}$ a.s.

\subsection{Mapping and Restriction}
$(E, \mathcal{E}), (F, \mathcal{F})$ Polish spaces, $\mu\ \sigma$-finite measure on $E$,  $T:E \to F$ meas, $T\#\mu $ push forward measure of $\mu $ under $T$ [$T\#\mu(B)=\mu(T^{-1}(B))$].

\begin{theorem}[]
	Assume that $T\#\mu$ is $\sigma$-finite. Let $N$ be a $ppp(\mu)$ on $E$, then $T\#N$ is a $ppp(T\#\mu)$ on $F$.
\end{theorem}

\begin{ex}[]
	$E=\mathbb{R},\ F=\mathbb{Z},\ T:E \to F; x \to \lfloor x \rfloor,\ \mu= \mathcal{L},\ T\#\mu=|.|$.
\end{ex}
\noindent
\textbf{Notation} If $\nu $ is a measure on $E$, $C \subset E$ meas.  $\nu _C: \nu(. \cap C)$

\begin{theorem}[Restriction]
	Let $C_1, C_2,... \subset E$ meas. and disjoint. If $N$ is a  $ppp(\mu)$ on  $E$, then $N_{C_1}, N_{C_2}...$ are indep $ppp$ with resp. intensities $\mu_{C_1}, \mu_{C_2},...$	
\end{theorem}

\subsection{Marking}
\noindent
\textbf{Motivation} Cars on a highway, at time 0 the position of the cars is a $ppp(1)$ on $\mathbb{R}$ (that means on average 1 car per kilometer of highway). We put an observer (Olga) at 0 on $\mathbb{R}$.

Case 1: All of the cars have speed 50km/h, we want to study $X=$ number of cars seen by Olga in 1 hour. What is the law of $X$? $X \sim Pois(50)$.

Case 2: The cars have a random speed $ \sim \mathcal{U}([50,100]) $. What is the law of $X$? It may at first seem complicated, but it is not!

\noindent
\textbf{Framework} $(E, \mathcal{E})$ Polish, $\mu=\sigma$-finite. $(F, \mathcal{F}, \nu )$ Polish, Probability space.
\begin{defn}
	Let $N=\sum_{i=1}^{\tau} \delta_{X_i}$ a $ppp(\mu)$ on $E$. $Y_i$ iid RV with law $\nu $ indep of $N$. The marked point process is the PP on $E \times F$ defined by $M=\sum_{i=1}^{\tau} \delta_{(X_i, Y_i)}$.
\end{defn}

\begin{rmk}[]
	$X_i$ corresponds to the position of the cars in Case 2, and $Y_i$ to their speeds.
\end{rmk}

\begin{theorem}[]
	The marked process is a $ppp(\mu \otimes \nu )$.
\end{theorem}

\noindent \textbf{Conclusion} The General PPP we have defined gives us a very general way to talk about a random processes on a large class of spaces (Polish), which fulfill a Markov-like property. This tool will allow us to make much stronger statements in more specific cases.

\section{Standard Poisson Process}
In discrete time processes $(X_n)_{n\in N}$, the law is characterised by the law of $(X_{n_1},..X_{n_k}; n_1...n_k \in \mathbb{N})$. In continuous time processes we have $(X_t)_{t\geq 0}$, we need to define $X_t:\forall t \in \mathbb{R}$ which is not countable.

\noindent \textbf{Outset} We would like to define a renewal process which also fulfills the Markov property, enabling us to not have. Furthermore we would like a simple continuous time process which is in some way a 'universal' stationary process on $\mathbb{R}_+ \to \mathbb{N}$ with independent increments and jumps of size 1. We would also like to see if any of the ideas from the previous chapter can be specified to this context.

\textbf{Applications} Queuing processes, insurance claims, compound Poisson process.

\textbf{Framework} $(\Omega, F, \mathbb{P})$ probability space, time space: $\mathbb{R}_{+}=[0,\infty)$ 

There are 2 points of view: random points on $\mathbb{R}_{+}$ (reminiscent of PPP) or continuous time stochastic process (renewal process).

\subsection{Exponential Random Variables}
\textbf{Note} We will use the 2nd point of view here.

\begin{defn}
	Let $\lambda> 0$, a real RV $T$ is exponential with parameter $\lambda$ (we write $T \sim Exp(\lambda)$) if it has density $f(t) = \lambda e ^{-\lambda t}\chi_{\{t\geq 0\}}$. $\iff \forall t\geq 0 \mathbb{P}_{} \left[ T>t \right] = e^{-\lambda t}$
\end{defn}

\begin{prop}[Memoryless Property]
	Let $\lambda > 0$ and $T \sim Exp(\lambda)$. Then  $\forall s,t\geq 0: \mathbb{P}_{} \left[ T>s+t | T>t \right] = \mathbb{P}_{} \left[ T>s \right] $
\end{prop}
\begin{prop}[Minimum of indep Exponentials]
	Let $n\geq 0, T_1...T_n$ indep with $T_i \sim Exp(\lambda_i), \lambda_i > 0$: 
\begin{itemize}
	\item  $min\{T_1...T_n\} \sim Exp(\lambda_1+...+\lambda_n)$
	\item $\mathbb{P}_{} \left[ T_1 = min\{T_1...T_n\} \right] = \frac{\lambda_1}{\lambda_1+...+\lambda_n}$
\end{itemize}

\end{prop}
 
\textbf{Reminder} $X$ a real RV with density $f$, $Y$ a RV with values in some measurable space $E$ indep of X. Then $\forall \phi:\mathbb{R} \times E \to \mathbb{R}$ meas + bdd we have: $\mathbb{E}_{} \left[ \phi(X,Y) \right] = \int_{0}^{\infty} \mathbb{E}_{} \left[ \phi(x,Y) \right] f(x) dx$ 

\begin{prop}[Sum of Exponentials]
	Let $\lambda > 0, n\geq 1$. Let $T_1...T_n$ be iid $Exp(\lambda)$ RVs. Then  $S_n = T_1+...+T_n$ is  $\Gamma(n, \lambda)$ distributed. ie $S_n$ is continuous with density $f_{S_n}(t)=\lambda e^{-\lambda t} \frac{(\lambda t)^{n-1}}{(n-1)!}$
\end{prop}

We can check that $\Gamma(1,t)=Exp(\lambda)$

\subsection{Definition of Poisson Processes}
\textbf{Setup}  $\lambda > 0, (T_i)_{i\geq 0}$ iid $Exp(\lambda ), S_n = T_1+...+T_n$

\begin{defn}
	The stochastic process $N=(N_t)_{t\geq 0}, N_t = \sum_{i=1}^{\infty} \chi_{S_i \leq t}$ is called the Poisson process with intensity $\lambda $ ($pp(\lambda)$). The RVs  $T_1,T_2,...$ are the inter-arrival times and  $S_1,S_2,...$ the arrival times/jump times.
\end{defn}
\noindent
\textbf{Elementary Properties}
\begin{itemize}
	\item The mapping $t \to N_t$ is a.s. right continuous, with values in $\mathbb{N}$
	\item For fixed $t\geq 0$ $N_t \sim Pois(\lambda t)$ ie $\mathbb{P}_{} \left[ N_t = n \right] = \frac{(\lambda t)^n}{n!}e^{- \lambda  t}$
\end{itemize}

\noindent
\textbf{Comment} "A property hold a.s." $\iff \exists$ meas set $A: \mathbb{P}_{} \left[ A \right] =1$ and $\forall \omega \in A$ the property holds. 


\subsection{Markov Property}
\begin{theorem}[Markov Property of N]
	Fix $t\geq 0$, the stochastic process $N^{(t)}=(N^{(t)}_{s})_{s \geq 0}$ defined by $N^{(t)}_s = N_{t+s}-N_{t}$ is a Poisson process, independent of $(N_u)_{0 \leq u \leq t}$.
\end{theorem}

\subsection{Stationary and Independent Increments}
\textbf{Motivation} We want to describe the law of $(N_{t_0},...,N_{t_k})$, the key here is that they are not totally independent. If we have 5 points at time $t_0$ then we know at time $t_1$ there will be at least 5 points. So we look at the law of $(N_{t_1}-N_{t_0},...,N_{t_k}-N_{t_{k-1}})$ ie the increments.

\begin{defn}
	A stochastic process $(X_t)_{t\geq 0}$ is said to have indep and stationary increments if 
\begin{itemize}
	\item $\forall k \geq 1, \forall 0=t_0 < ... < t_k: X_{t_1}-X_{t_0}, ..., X_{t_k}- X _{t_{k-1}}$ are indep
	\item $\forall  s<t, \forall  n \geq 0: X_t - X_s \stackrel{law}{=} X _{t+h}-X_{s+h}$
\end{itemize}

\end{defn}

\begin{theorem}[Marginals of Poisson Process]
We have the following:
\begin{enumerate}
	\item $\forall k \geq 1, \forall 0=t_0<...<t_k: N_{t_1}-N_{t_0},...,N_{t_k}- N_{t_{k-1}}$ are indep
	\item $\forall s \leq t: N_t - N_s \sim Pois(\lambda (t-s))$
\end{enumerate}
In particular $N=(N_t)_{t\geq 0}$ has indep and stationary increments.
	
\end{theorem}

We know the law of $(N_{t_1},...,N_{t_k}$ for every fixed $t_1...t_k$. 
\begin{align}
	\mathbb{P}_{} \left[ N_{t_1}=m_1...N_{t_k}=m_k \right] =& \mathbb{P}_{} \left[ N_{t_1}=m_1, N_{t_2}-N_{t_1}=m_2 - m_1,..., N_{t_k}-N_{t_{k-1}}=m_k - m_{k-1} \right] \nonumber \\ 
	=& \prod_{i=1}^{k}\frac{(\lambda (t_0 - t_{i-1}))^{m_i-m_{i-1}}}{m_i - m_{i-1}} e^{- \lambda (t_i - t_{i-1})}
\end{align}

\subsection{Finite Marginals Characterization}
\textbf{Motivation}  Let $(N_t)_{t\geq 0}$ a stochastic process. Does the last formula from above ensure that the process is $pp(\lambda)$? No, we can define $\tilde{N}_t =  \sum_{i \geq 1}^{} \chi_{S_i<t} $, we could also just change the value of the process as some random points, thus when we fix $t_1,...,t_k$ we have 0 probability to see these.

In order to get a characterization we need to add some regularity assumptions.

\begin{defn}
	Let $N=(N_t)_{t \geq 0}$ be a continuous stoch process with values in $\mathbb{R}$. We say that $N$ is a counting process if the following holds a.s.:
\begin{enumerate}
	\item $N_0 = 0$ a.s.
	\item  $t \to N_t$ is non decreasing, right continuous, with values in $\mathbb{N}$ \label{continCond}
\end{enumerate}
In this case, we can define the jump times by setting $S_1=min\{t: N_t >0\}$ and by induction  $S_{i+1}= min\{t \geq S_i: N_t > N_{S_i}\}$.
\end{defn}

\begin{ex}[]
	$pp(\lambda )$ is a counting process.
\end{ex}

\begin{rmk}[]
	The condition \ref{continCond} is almost sure in the following manner: $\exists A$ meas. with $\mathbb{P}_{} \left[ A \right] =1$ st $\forall \omega \in A: t \to N_t(w)$ is non decreasing, right continuous, with values in $\mathbb{N}$.
\end{rmk}

\begin{theorem}[]
	Let $\lambda> 0:$ Let $N$ be a counting process, the following are equivalent:
\begin{enumerate}
	\item $N$ is $pp(\lambda)$
	\item $\forall k \geq 1, \forall t_0 =0 < t_1 <...<t_k, \forall n_1,...,n_k \in \mathbb{N}:$ \\ $\mathbb{P}_{} \left[ N_{t_1}-N_{t_0}=n_1,...,N_{t_k}-N_{t_k-1}=n_k \right] = \prod_{i=1}^k \frac{(\lambda (t_i - t_{i-1}))^{n_i}}{n_i!} e^{-\lambda (t_i - t_{i-1})} $
\end{enumerate}

\end{theorem}

\begin{rmk}[]
	By def $N$ is a $pp(\lambda)$ $\iff $ $N$ is a counting process with jumps of size 1 a.s. and  $S_1,S_2-S_1,...$ are iid  $exp(\lambda)$.
\end{rmk}

\subsection{Microscopic Characterization}
\begin{theorem}[]
	Let $N$ be a counting process, let $\lambda> 0$. TFAE:
\begin{enumerate}
	\item $N$ is $pp(\lambda)$ 
	\item $N$ has indep and stationary increments and $\mathbb{P}_{} \left[ N_t =1 \right] = \lambda t + o(t)$ and $\mathbb{P}_{} \left[ N_t \geq 2 \right] = o(t)$
\end{enumerate}

\end{theorem}

\subsection{Properties of Poisson Process}

\begin{theorem}[Law of Large Numbers]
Let $N$ be a $pp(\lambda), \lambda > 0$, then: $lim_{t \to \infty} \frac{N_t}{t}=\lambda$.
\end{theorem}

\textbf{Motivation} If we want to specify (and remove) certain points, for instance if the PP is describing arrival times at a bakery then say we want to differentiate between customers who are younger than 45 and those who are older. If we just look at one of these groups, what type of process are they?

\begin{theorem}[Thinning]
	Let $(N_t)_{t\geq 0} \sim pp(\lambda)$ with jump times $(S_i)_{i\geq 0}$. Let $(X_i)_{i\geq 0}$ iid $Ber(p)$ indep of $N$ (this is the differentiation, called the marking of $N$). Define $N_t^1 = \sum_{i\geq 1}^{} \chi_{S_i \leq t, X_i = 1}$ and $N_t^0 = \sum_{i \geq 1}^{} \chi_{S_i \leq t, X_i = 0}$.
\\ \noindent	
	$(N_t^0)$ and  $(N_t^1)$ are indep Poisson processes with respective rates  $\lambda_0 = (1-p)\lambda, \lambda _1=p\lambda $.
\end{theorem}

Let $(N_t^0)$ and $(N_t^1)$ be indep Poisson processes with respective rates $\lambda_0> 0, \lambda_1> 0$. Let $N_t = N_t^0 + N_t^1$.
\begin{theorem}[]
$N_t$ is a counting process and we define for every $i $: $X_i = \mathbbm{1}_{\textrm{\{i'th jump of }N_t\textrm{ is a jumping time of }N_t^1\}}$. Then  $N_t$ is a $pp(\lambda_0 + \lambda_1)$ and  $(X_i)$ is a marking of  $N$ with $\forall i: \mathbb{P}_{} \left[ X_i=1 \right] = \frac{\lambda_1}{\lambda_0+\lambda_1}$.
\end{theorem}

\noindent \textbf{Conclusion} We successfully defined a renewal process with the Markov property, we also found that this object is also a PPP, thus giving us a process which has the asymptotic behavior (LLN, etc) from the renewal process perspective and getting the Strong and Weak Markov Property from the Poisson Point Process perspective. 

\section{Continuous Time Markov Chains}

\textbf{Framework} $(\Omega, \mathcal{F}, \mathbb{P}_{} ) $ Probability space, $E$ finite or countable. 

\noindent \textbf{Outset} We will now be extending the theory of Discrete Markov Chains developed in Chapters 1 and 2 and generalizing the theory of Poisson Processes in Chapter 5. Instead of jumping at every step (studying $(X_n)_{n \in \mathbb{N}})$, we will now make jumps at random times on $\mathbb{R}_+$ with the continuous time MC $(X_t)_{t\geq 0}$ using times on $\mathbb{R}_+$. 
\begin{tabular}{p{0.5\textwidth}  | p{0.5\textwidth}}
\textbf{Discrete Time MC} & \textbf{Continuous Time MC} \\ 	
\hline
Time & \\ $\mathbb{N}$ &  $\mathbb{R}_+$ \\
\hline
Initial Distribution & \\ $X_0 \sim \mu$ &  $X_0 \sim \mu$ \\
\hline
Memoryless Property & \\
\begin{align*}
\mathbb{P}_{} \left[ X_{n+1}=x_{n+1} | X_0 = x_0,...,X_n=x_n \right]= \\ \mathbb{P}_{} \left[ X_{n+1} = x_{n+1} | X_n= x_{n} \right] 
\end{align*}
&  
\begin{gather*}
	\forall t_0<...<t_{n+1} \\ \mathbb{P}_{} \left[ X_{t_{n+1}} = x_{n+1} | X_{t_0}=x_0,...,X_{t_n}=x_n \right] = \\ \mathbb{P}_{} \left[ X_{t_{n+1}}| X_{t_n}=x_{n} \right]  
\end{gather*} \\
\hline
Transition Probabilities & \\ $\mathbb{P}_{} \left[ X_{n+1} = y | X_n = x \right] = p _{x,y} $ & $\mu$-scopic generation, $x \neq y$, $ \mathbb{P}_{} \left[ X_{t+h}=y | X_{t}=x \right] = q_{x,y}*h + o(h)$. So for $h$ small the probability of staying at $x$ is equal to 1. \\


\end{tabular}

\subsection{Definition via Generator}
\begin{defn}
	Let $X = (X_t)_{t\geq 0}$ be a cont. time stochastic process with values in $E$. We say that $X$ is a jump process without explosion if a.s.
\begin{enumerate}
	\item $t \mapsto X_t$ is right continuous 
	\item $\forall t >0 $ the number of discontinuity points of $s \mapsto X_s$ on $[0,t]$ is finite.
\end{enumerate}

\end{defn}

\begin{defn}
	Jump times: $S_0 =0, S_{i+1} = inf\{t > S_i, X_t = X_{S_i}\}$, with condition (ii) implying that $S_n \to \infty $ as $n \to \infty $ a.s.
\end{defn}

\begin{defn}
	Skeleton: $\forall n \in \mathbb{N}: \bar{X_n} := X_{S_n}$ if $S _n< \infty$, if $\exists n_0: S_n = \infty \ \forall n \geq n_0$ then $\forall n \geq n_0: X_n = X_{n_0 -1}$.
\end{defn}

\begin{defn}
	A generator (Q-matrix) is a family $q=(q_{xy})_{x,y \in E}$ where:
	\begin{enumerate}
		\item $q_{xy} \geq 0 \forall x \neq y$
		\item $\forall x: \sum_{y \neq x}^{} q_{xy} < \infty$
		\item $q_{xx}= -q(x) =  -\sum_{y \neq x}^{} q_{xy}$
\end{enumerate}

\end{defn}


\begin{defn}
	Let $\mu $ be a distribution on $E$, $q$ a generator, let $X$ be a jump process without explosion. We say that $X$ is a $CTMC(\mu, q)$ (Continuous Time Markov Chain without explosion with initial distribution $\mu $ and generator $q$ ) if:
\begin{enumerate}
	\item $X_0 \sim \mu $ 
	\item $\forall t_1 <...t_{n+1}: \forall x_1,...,x_{n=1} \in E: \mathbb{P}_{} \left[ X_{t_{n+1}} = x_{n+1} | 
		X_{t_1}=x_1,...,X_{t_{n}}=x_n \right] = \mathbb{P}_{} \left[ X_{t_{n+1}} = x_{n+1} | X_{n}=x_n \right] $
	\item $\forall x,y \in  E: \forall t> 0:$ as $h \to 0^+$:  $\mathbb{P}_{} \left[ X_{t+h}=y | X _{t}=x \right]  = \delta_{xy} + q_{xy}h + o(h)$ uniformly in $t\geq 0, y \in E$.
\end{enumerate}

\end{defn}

\begin{rmk}[]
	In (iii): $\forall x, \exists \varphi_x: \mathbb{R}_+ \to \mathbb{R}_+$ st $\varphi_x(h) \stackrel{h \to 0^+}{\to}0$ and $\forall h> 0, \forall y \in E: \mathbb{P}_{} \left[ X_{t+h}=y |  X_{t}=x \right] = 
	\begin{cases}
		1 - q(x)h + h \varphi_{x,x,t}(h) \\
		q_{xy}h + h \varphi_{x,y,t}(h)
	\end{cases}
	$ where $0 \leq \varphi_{x,z,t}(h) \leq \varphi_x(h)$.
\end{rmk}

\begin{ex}[Poisson Process]
	Let $(N_t)_{t\geq 0}$ be a $pp(\lambda)$. Then  $N$ is a $CTMC(\mu, q)$ with  $\mu = \delta_0$ and $q=(q_{xy})_{x,y \in \mathbb{N}}=$ $\lambda$ if $y=x+1$,  $-\lambda$ if  $y=x$, and  $0$ otherwise.
\end{ex}

\textbf{Question} Does $CTMC(\mu, q)$ exist for arbitrary $\mu $ and $q$?

\subsection{Non-Rigorous Section: The Constructive Approach}
\begin{ex}[2 State Markov Chain]
	$E=\{1,2\}$,  $q=
	\begin{pmatrix}
		-\alpha & \alpha \\
		\beta & -\beta
	\end{pmatrix}$, $\alpha, \beta > 0$.
	$(X_t)_{t\geq 0}, X_t \sim CTMC(\delta_1, q)$?
	$X_0 =1$, $T_1 \sim Exp(\alpha)$, $T_2 \sim Exp(\beta)$ (see notes for reasoning). This gives us the candidate $X_t = 
\begin{cases}
1, t \in [S_i, S_{i+1}) \\
2, t \in [S_{i+1}, S_{i+2}) \\
\end{cases}
$.
\end{ex}

\textbf{Idea} $q_{xy}$ should represent the parameter for the time taken to jump from $x$ to $y$. Since we want our process to have the Markov property, it is natural to see $q_{xy}$ as the parameter in the exponential RV representing the waiting time to jump from $x$ to $y$.

\begin{ex}[3 State Markov Chain]
	We start at $X_0 =1$, we have probability  $\alpha $ to jump to 2, and probability $\beta $ to jump to 3. Thus we have $T_{12} \sim Exp(\alpha)$, $T_{13} \sim Exp(\beta )$, then we shall actually jump at $T_1 = min\{T_{12}, T_{13}\} \sim Exp(\alpha + \beta )$. $\mathbb{P}_{} \left[ \textrm{jump from } 1 \to 2 \right] = \mathbb{P}_{} \left[ T_1 = T_{12} \right]= \frac{\alpha }{\alpha + \beta } = \frac{q_{12}}{q(1)} $. The skeleton $(\overline{X_n})$ is a Discrete time MC with transition probabilities $\kappa_{xy}= \frac{q_{xy}}{q(x)}$. 
\end{ex}

\subsection{Definition by Skeleton and Holding Time}
\textbf{Note} $q$ is a fixed generator.
\subsubsection{Discrete Chain Associated to 2}
\begin{defn}
	Let $x,y \in E$, if $q(x)> 0$ we define $\kappa_{xy}= \frac{q_{xy}}{q(x)}$ and $\kappa_{xx}=0$, if $q(x)=0$ then $\kappa_{xy}= 
	\begin{cases}
		0, x \neq y \\
		1, x =y 
	\end{cases}
	$.
\end{defn}

\begin{rmk}[]
	$\kappa $ is transition probability (check for the cases where $q(x) = 0$ and $q(x)\neq 0$). 
\end{rmk}

\begin{ex}[]
\begin{enumerate}
	\item The $pp(\lambda)$, with $\kappa_{i,i+1}=1$.
	\item The 2-State MC, with $\kappa_{1,2}=\kappa_{2,1}=1$ 
	\item The 3-State MC, more complicated (see notes).
\end{enumerate}

\end{ex}

\subsubsection{Something can go wrong}
Let $\mu $ probability measure on $E$, $q$ generator. Our goal is to define $(X_t)$ a $CTMC(\mu, q)$. Let $Y= (Y_n)$ be a discrete $MC(\mu, \kappa)$, $H_1, H_2,...$ iid $Exp(1)$ RVs, set $T_i = \frac{1}{q(Y_i)} H_i$, conditional on $Y$ $T_i \sim Exp(q(Y_i))$ and they are independent.

We define $S_i = T_1 + T_2 + ... + T_i$ for $i>1$, and $X_t = Y_n$ if $t \in [S_n, S_{n+1})$. Now have we defined $X_t$ for all $t\geq 0$? No, as $lim_{n \to \infty }S_n $ could be finite. 

\begin{defn}
	We say that $q$ has no explosion if $\forall $ choice of $\mu: S_{ \infty } = + \infty $ a.s.
\end{defn}

\begin{rmk}[]
	This is only a condition on $q$.
\end{rmk}

\textbf{Question} Does there exist $q$ with explosion? (Answer later)

\textbf{Question} If $q$ has no explosion, is $(X_t)$ a $CTMC(\mu, q)$? (Also later)

\subsubsection{Birth Chain}
$E= \mathbb{N}$, fix $(\lambda_i)_{i\geq 1}$, and $q_{i,i+1}= \lambda_i$, $q_{i,i}=-\lambda_i$, and otherwise $q_{i,j}=0$. We get that $\kappa_{i,j}= \delta_{i, i-1}$, $Y_n = n$, and $T_i \sim Exp(\lambda_i)$. Now we set $S_{\infty} = \sum_{i=1}^{\infty} T_i$ and we ask, is $S_\infty < \infty$ or $S_\infty = \infty$ a.s.

\begin{rmk}[]
	$pp(\lambda)$ is a birth chain with  $\lambda_i = \lambda$.
\end{rmk}

\begin{theorem}[]
	The birth chain $q$ has no explosion $\iff$ $\sum_{i\geq 1}^{} \frac{1}{\lambda_i} = \infty$.
\end{theorem}

\subsubsection{Non-Explosion Characterization} 
Fix $q$ a generator on $E$ ($\kappa_{xy}= \frac{q_{xy}}{q(x)}$).

\begin{theorem}[]
	For $x \in E$, let $Y=(Y_n^{(x)})_{n\geq 0}$ be a $MC(\mu, \kappa )$. Then $q$ has no explosion $\iff \forall x \sum_{n\geq 0}^{} \frac{1}{q(Y_n^{(x)})} < \infty $ a.s.
\end{theorem}

\begin{rmk}[]
	$ \sum_{n\geq 0}^{} \frac{1}{q(Y_n)}$ is a RV.
\end{rmk}
\noindent
\textbf{Application} Sufficient Condition: $q$ is non-explosive if
\begin{itemize}
	\item $E$ is finite (2 and 3 State MC)
	\item $inf_{x \in E:\ q(x) \neq 0}q(x) > 0 $ (Poisson, 2 and 3 State MC)
	\item The chain $\kappa $ is irreducible and recurrent.
\end{itemize}

\subsubsection{Key Theorem}

\begin{theorem}[Characterization of CTMC]
Let $X=(X_t)_{t\geq 0}$ be a jump process without explosion. Let $q$ be a non-explosive generator. Then TFAE:
\begin{enumerate}
	\item $X$ is a $CTMC(\mu, q)$
	\item The skeleton of $X$ ($Y= \overline{X_n})$is a discrete time $MC(\mu, \kappa ) $ and conditioned on $Y$, the holding times satisfy $S_i-S_{i-1} \sim Exp(q(Y_i))$ are indep. 
\end{enumerate}

\end{theorem}
\textbf{Consequences} 
\begin{itemize}
	\item Existence of CTMC	 for non-explosive $q$ 
	\item Uniqueness of the law of a $CTMC(\mu, q)$ (if $X, Y$ are $CTMC(\mu,q )$ then $\forall t_1<...<t_n: (X_{t_1},...,X_{t_n} \sim (Y_{t_1},..., Y_{t_n})$)
	\item There exist constructive algorithms (see Morris)
\end{itemize}

\subsection{Markov Properties}
\noindent
\textbf{Framework} $(\Omega, \mathcal{F}, (\mathbb{P}_{x})_{x \in E}) $, $(X_t)_{t\geq 0}$ st under $\mathbb{P}_{x}$, $X$ is  $CTMC(\mu, q)$ with $q$ non-explosive. (Such probability measures exist, take $\mu $ with $\mu (x)> 0 \forall x \in E$, consider $(X_t)_{t\geq 0}=CTMC(\mu,q)$ then let $\mathbb{P}_{x} = \mathbb{P}_{} \left[ . | X_0 =x \right]  $.)

\textbf{Simple Markov Property} Fix $t\geq 0, x \in E$; Conditionally on $X_t =x$ we have that $(X_{t_s})_{s \geq 0}$ is a $CTMC(\delta_x, q)$ indep of $(X_n)_{n \leq t}$

\textbf{Strong Markov Property}
The same applies if we replace $t$ by a random stopping time $T$.

\subsection{Transition Probabilities}
$X=(X_t)_{t\geq 0}$ is a $CTMC(\delta_x, q)$ under $\mathbb{P}_{x} $, then we define for $t\geq 0$ and $x,y \in E$: $p_{xy}(t)= \mathbb{P}_{x} \left[ X_t =y \right] $. In the discrete case this corresponds to $p_{xy}^{(n)}= p_{xy}(t)$.

\begin{rmk}[] We have
\begin{itemize}
	\item $\forall t\geq 0: (p_{xy}(t))_{x,y \in E}$ is a transition probability $\sum_{y}^{} p_{xy}(t) = \sum_{y}^{} \mathbb{P}_{x} \left[ X_t=y \right] =1$.
	\item $\forall x: p_{xx}(t) \geq e^{-q(x) t} \forall t$
	\item $\forall x,y \in E: p_{xx}(h) = 1 - q(x)h + o(h)$ and $p_{xy}(h)=q_{xy}h+o(h)$ for $x \neq y$.
\end{itemize}

\end{rmk}

\begin{prop}[Chapman Kolmogorov (CK) Equations]
	$\forall t,s \geq 0: p_{xy}(t+s)=\sum_{z}^{} p_{xz}(t)p_{zy}(s)$	
\end{prop}
\noindent
\textbf{Question} Knowing $q$, what is $p_{xy}(t)$?

\begin{theorem}[Backward/Forward equations]
	$\forall x,y \in E: p_{xy}$ is $C^1$ on $\mathbb{R}_+$ and $\forall t \geq 0$ we have the backward equation:
\begin{align}
 p_{xy}'(t) = \left( \sum_{z \neq x}^{} q_{xy} p_{zy}(t) \right) - q(x) p_{xy}(t)
\end{align}
And the forward equation:
\begin{align}
	 p_{xy}'(t) = \left( \sum_{z \neq y}^{} p_{xz}(t)q_{zy} \right) - p_{xy}(t)q(y)
\end{align}
	
\end{theorem}

\textbf{Application} Let us look at what happens when $E$ is finite ($E = \{1...k\}$). Then $P(t) = 
\begin{pmatrix}
	p_{11}(t) & ... & p_{1k}(t) \\
	\vdots & & \vdots \\
	p_{k1}(t) & ... & p_{k k}(t)
\end{pmatrix}$ 
and $Q = 
\begin{pmatrix}
	q_{11} & ... & q_{1k} \\
	\vdots & & \vdots \\
	q_{k1} & ... & q_{k k }
	
\end{pmatrix}$
So we get that $p_{xy}'(t) = \sum_{z \in E}^{} q_{xz}p_{zy}(t) \implies P'(t) = Q P(t)$ (from backward equation) we also get $P'(t) = P(t)Q$ (from forwards equation).

\begin{theorem}[]
	If $E$ is finite, we have $\forall t\geq 0: P(t) = exp(tQ)$.
\end{theorem}


\end{document}

